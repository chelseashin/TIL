# 자료구조&알고리즘

##### Array

- 논리적 저장 순서, 물리적 저장 순서 일치 인덱스 알고 있으면 O(1)에 탐색 가능(random access 가능)
- 중간 원소 삭제 할라면 배열의 연속적인 특징이 깨짐, 뒤에 원소들 다 당겨줘야함 O(n)
- 삽입도 중간에 추가할라면 뒤로 다 밀어줘야함 O(n)

##### Linked List

- 자기 다음 원소 어떤건지 기억. 이 연산은 O(1)에 가능 하지만, 어디에 있는지 찾을라면 결국 O(n)
- 근데 찾아볼라면 O(n) 걸림
- Tree의 근간이 되는 자료구조로 Tree를 다룰때 그 유용성이 드러남

##### HashTable

::key, value 1:1로 연관지어 저장하는 자료구조

[![hashtable](https://github.com/WeareSoft/tech-interview/raw/master/contents/images/hashtable.png)](https://github.com/WeareSoft/tech-interview/blob/master/contents/images/hashtable.png)

Hash 충돌

- 서로 다른 Key가 Hash Function에서 중복 Hash로 나오는 경우
- 충돌이 많아질수록 탐색의 시간 복잡도가 O(1)에서 O(n)으로 증가

해결 방법

1. Separating Chaining

   - JDK 내부에서 사용하는 충돌 처리 방식

   - Linked List(데이터 6개 이하) 또는 Red-Black Tree(데이터 8개 이상) 사용, 트리는 기본적으로 메모리 사용량이 많기 때문에 데이터 개수가 적을 때 Worst Case 를 살펴보면 트리와 링크드 리스트의 성능 상 차이가 거의 없음, 따라서 적으면 그냥 링크드 리스트 사용. **데이터가 적다는 것은 얼마나 적다는 것을 의미하는가?** 앞에서 말했듯이 기준은 하나의 해시 버킷에 할당된 key-value 쌍의 개수이다. 이 키-값 쌍의 개수가 6 개, 8 개를 기준으로 결정한다. 기준이 두 개 인것이 이상하게 느껴질 수 있다. 7 은 어디로 갔는가? 링크드 리스트의 기준과 트리의 기준을 6 과 8 로 잡은 것은 변경하는데 소요되는 비용을 줄이기 위함이다. **한 가지 상황을 가정해보자.** 해시 버킷에 **6 개** 의 key-value 쌍이 들어있었다. 그리고 하나의 값이 추가되었다. 만약 기준이 6 과 7 이라면 자료구조를 링크드 리스트에서 트리로 변경해야 한다. 그러다 바로 하나의 값이 삭제된다면 다시 트리에서 링크드 리스트로 자료구조를 변경해야 한다. 각각 자료구조로 넘어가는 기준이 1 이라면 Switching 비용이 너무 많이 필요하게 되는 것이다. 그래서 2 라는 여유를 남겨두고 기준을 잡아준 것이다. 따라서 데이터의 개수가 6 개에서 7 개로 증가했을 때는 링크드 리스트의 자료구조를 취하고 있을 것이고 8 개에서 7 개로 감소했을 때는 트리의 자료구조를 취하고 있을 것이다.

   - Linked List 사용 시 충돌이 발생하면 충돌 인덱스가 가리키고 있는 Linked List에 노드 추가하여 value 삽입

   - Key에 대한 Value 탐색 시에는 인덱스가 가리키고 있는 Linked List를 선형 검색하여 Value 반환 (삭제도 마찬가지)

   - Linked List 구조를 사용하기 때문에 추가 데이터 수 제약이 적은편
   - 보조 해시 함수(supplement hash function)써서 key의 해시 값을 변형하여 해시 충돌 가능성을 줄임

2. Open addressing

   - 추가 메모리 공간을 사용하지 않고, HashTable 배열의 빈 공간을 사용하는 방법
   - Separating Chaining 방식에 비해 적은 메모리 사용
   - 방법은 Linear Probing, Quadratic Probing, Double Hashing
   - 단점은 삭제가 어렵다는 것인데, 삭제를 했을 경우 충돌에 의해서 뒤로 저장된 데이타는 검색이 안될 수 있다. 이런 문제를 방지하기 위해서 우측과 같이 데이타를 삭제한 후에, Dummy node를 삽입한다. 이 Dummy node는 실제 값을 가지지 않지만, 검색할때 다음 Index까지 검색을 연결해주는 역할, 이것도 근데 많아지면 부하 -> 중복되는 값의 끝 값을 삭제하는 곳에 넣을수도
   - Linear Probing:: h(k), h(k)+1, h(k)+2, ... 순서대로
   - Quadratic Probing:: h(k), h(k)+1^2, h(k)+2^2, h(k)+3^2, ... 순서대로
   - Double Hasing::서로 다른 두 해시함수 h1과 h2 사용, h(k, i) = (h1(k) + i*h2(k))%m, **1차 해쉬 함수는**  기존의 역할과 같이 키를 근거로 저장위치를 결정한다. **2차 해쉬 함수**는 충돌 발생시 몇 칸 뒤를 살필지 결정한다.

3. Resizing
   - Open addressing의 경우, 고정 크기 배열을 사용하기 때문에 데이타를 더 넣기 위해서는 배열을 확장해야 한다. 또한 Separate changing에 경우에도 버킷이 일정 수준으로 차 버리면 각 버킷에 연결되어 있는 List의 길이가 늘어나기 때문에, 검색 성능이 떨어지기 때문에 버킷의 개수를 늘려줘야 한다. 이를 Resizing이라고 하는데, Resizing은 별다른 기법이 없다. 더 큰 버킷을 가지는 array를 새로 만든 다음에, 다시 새로운 array에 hash를 다시 계산해서 복사해줘야 한다.
   - 해시 버킷 크기를 두 배로 확장하는 임계점은 현재 데이터 개수가 해시 버킷의 개수의 75%가 될 때이다. `0.75`라는 숫자는 load factor 라고 불린다.

tip) 해쉬테이블의 get(key)과 put(key)에 간단하게, 캐쉬 로직을 추가하게 되면, 자주 hit 하는 데이타에 대해서 바로 데이타를 찾게 함으로써, 성능을 간단하게 향상 시킬 수 있다.

##### Stack

:: LIFO(Last In First Out)

- 사용 사례: 재귀, 뒤로가기, undo, 역순 문자열, 수식 괄호검사, 후위표기법 계산(피연산자이면 push, 연산자이면 두개 뽑아서 계산(아래 있는게 앞에 있는 수)해서 결과 값push)

##### Queue

::FIFO(First In First Out)

- 사용 사례: BFS, Cache, 인쇄 대기열 등

##### Graph

::노드와 그를 연결하는 간선을 하나로 모아 놓은 자료구조, 객체 간의 관계를 표현할 수 있는 자료구조

- 구현

  - 인접 행렬 (adjacent matrix) : 정방 행렬을 사용하는 방법

  해당하는 위치의 value 값을 통해서 vertex 간의 연결 관계를 O(1) 으로 파악할 수 있다. Edge 개수와는 무관하게 V^2 의 Space Complexity 를 갖는다. Dense graph 를 표현할 때 적절할 방법이다.

  - 인접 리스트 (adjacent list) : 연결 리스트를 사용하는 방법

  vertex 의 adjacent list 를 확인해봐야 하므로 vertex 간 연결되어있는지 확인하는데 오래 걸린다. Space Complexity 는 O(E + V)이다. Sparse graph 를 표현하는데 적당한 방법이다.

##### MST (Minimum Spanning Tree)

::그래프 G 의 spanning tree 중 edge weight 의 합이 최소인 `spanning tree`를 말한다. 여기서 말하는 `spanning tree`란 그래프 G 의 모든 vertex 가 cycle 이 없이 연결된 형태

- Kruskal: edge 정렬하고 앞에서부터 cycle 안생기게 추가해나감 O(ElogE)
- Prim: 내부에 있는 vertex로부터 외부에 있는 vertex사이의 edge를 연결하는데 그 중 가장 작은 weight의 edge를 통해 연결되는 vertex를 추가 O(ElogV)

##### Tree

:: 컴포넌트가 하나이고, 방향 무시했을 때 싸이클 존재하지 않는 그래프 (비선형 자료구조로 계층적 관계를 표현 ex]디렉토리 구조, 조직도)

- 특징: 계층 모델, DAG(directed Acyclic Graphs)의 한 종류, 노드 N개면 N-1개의 간선, 루트에서 어떤 노드로 가는 경로 유일, 한 개의 루트 노드만이 존재하며 모든 자식 노드는 한개의 부모 노드만을 가짐



##### Heap(Binary)

:: 완전 이진 트리(complete binary tree)의 일종으로 우선순위 큐를 위하여 만들어진 자료구조, 최댓값 or 최솟값을 빠르게 찾을 수 있음, 중복된 값 허용(BST는 중복된 값 허용 x ==> 검색을 목적으로 하는 자료구조이기 때문에 중복이 많을 수 있는 경우 굳이 트리에 중복노드를 삽입해서 검색 속도를 느리게 할 필요가 없기 때문이다. 굳이 중복을 허용하는 이진탐색트리를 만들 필요가 있을까? 합당한 이유가 있다면 굳이 중복된 노드를 트리에 삽입하는 것 보다는 노드에 count 값을 가지게 하는 것으로 처리하는 게 효율적이라고 생각한다.)

- 구현
  1. 인덱스:: Complete Binary Tree 이므로 배열 편함, 루트 노드 인덱스를 1이라 했을 때 왼쪽 자식 인덱스 = parent\*2, 오른쪽 자식 인덱스 = parent\*2+1, 부모 인덱스 = (int)(child/2)
  2. 삽입:: 마지막 노드에 추가 후, 새로운 노드를 부모 노드들과 비교하여 올바른 위치에 가도록(heapify)
  3. 삭제:: 루트 노드 마자막 노드 바꾸고 마지막 원소 삭제, 루트에서부터 heapify



##### BST(Binary Search Tree)

규칙 1. 이진 탐색 트리의 노드에 저장된 키는 유일하다.

규칙 2. 부모의 키가 왼쪽 자식 노드의 키보다 크다.

규칙 3. 부모의 키가 오른쪽 자식 노드의 키보다 작다.

규칙 4. 왼쪽과 오른쪽 서브트리도 이진 탐색 트리이다.

문제점: 한쪽으로 쏠리면 삽입,삭제,탐색 모두 O(n)됨, 해결책으로 균형잡힌트리(RBTree, BTree, AVLTree, Treap 등)



##### RBT(Red Black Tree)

- 삽입 요약

우선 BST 의 특성을 유지하면서 노드를 삽입을 한다. 그리고 삽입된 노드의 색깔을 **RED 로** 지정한다. Red 로 지정하는 이유는 Black-Height 변경을 최소화하기 위함이다. 삽입 결과 RBT 의 특성 위배(violation)시 노드의 색깔을 조정하고, Black-Height 가 위배되었다면 rotation 을 통해 height 를 조정한다. 이러한 과정을 통해 RBT 의 동일한 height 에 존재하는 internal node 들의 Black-height 가 같아지게 되고 최소 경로와 최대 경로의 크기 비율이 2 미만으로 유지된다.

- 삭제 요약

삭제도 삽입과 마찬가지로 BST 의 특성을 유지하면서 해당 노드를 삭제한다. 삭제될 노드의 child 의 개수에 따라 rotation 방법이 달라지게 된다. 그리고 만약 지워진 노드의 색깔이 Black 이라면 Black-Height 가 1 감소한 경로에 black node 가 1 개 추가되도록 rotation 하고 노드의 색깔을 조정한다. 지워진 노드의 색깔이 red 라면 Violation 이 발생하지 않으므로 RBT 가 그대로 유지된다.

Java Collection 에서 ArrayList 도 내부적으로 RBT 로 이루어져 있고, HashMap 에서의 `Separate Chaining`에서도 사용된다. 그만큼 효율이 좋고 중요한 자료구조이다.

- 특징

1. 삽입, 삭제, 탐색 최악의 경우에도 O(logn)
2. 각 노드는 하나의 key, 왼쪽자식(left), 오른쪽자식(right), 부모노드(p)의 주소 저장
3. 자식 노드 존재하지 않을 경우 NIL노드 라고 부르는 특수한 노드가 있다고 가정
4. 따라서 모든 리프노드는 NIL노드
5. 실제로 구현시 NIL노드 포함하지 않고, 개념적인 설명을 좀 더 편하게 하기위해 사용함

   즉, 아래 그림에서 개념적으로는 (b)처럼 되지만 실제 구현은 (c)처럼 됨

[![img](https://github.com/namjunemy/TIL/raw/master/Algorithm/img/red_black_01.png?raw=true)](https://github.com/namjunemy/TIL/blob/master/Algorithm/img/red_black_01.png?raw=true)

- 정의
  - 각 노드는 red 혹은 black
  - 루트노드는 black
  - 모든 리프노드(즉, NIL 노드는) black
  - red노드의 자식노드들은 전부 black(즉, red노드는 연속되어 등장하지 않음)
  - 모든 노드에 대해 그 노드로부터 자손인 리프노드에 이르는 모든 경로에는 동일한 개수의 black 노드가 존재

- RBTree의 높이
  - 노드 x의 높이 h(x)는 자신으로부터 리프노드(NIL노드)까지의 가장 긴 경로에 포함된 엣지의 개수
  - 노드 x의 블랙-높이 bh(x)는 x로부터 리프노드(NIL노드) 까지의 경로상의 블랙노드의 개수(노드 x 자신은 불포함)
  - 높이가 h인 노드의 블랙-높이는 bh >= (h/2)이다. (레드노드는 연속될 수 없으므로 당연히 블랙노드의 수가 높이의 절반 이상임)
  - 노드 x를 루트로하는 임의의 서브트리는 적어도 (2^bh(x))-1개의 내부노드를 포함(수학적 귀납법)
  - 위의 두가지 증명으로 설명 가능한 것은, n개의 내부노드를 가지는 RBTree의 높이는 2loh(n+1) 이하(n >= (2^bh)-1 >= (2^h/2)-1)
  - 즉, 정의에서 설명하는 5가지 조건을 만족하는 레드블랙트리라면 자동으로 높이는 O(logn)이 됨

- Left and Right Rotation(돌려돌려~)
  - 한 노드를 중심으로 부분적으로 트리의 모양을 수정하는 연산
  - 아래 pesudo code 차례대로 실행하면 되므로 시간복잡도 O(1)
  - 이진탐색트리의 특성을 유지함(Rotate를 해서 서브트리가 옮겨지도라도, BST의 특성 유지)
  - x와 y의 자식들은 모두 서브트리임

![img](https://github.com/namjunemy/TIL/raw/master/Algorithm/img/red_black_03.png?raw=true)

- Left Rotation ( y = right[x] != NIL이고, 루트노드의 부모 NIL 이라고 가정)
  - x의 오른쪽 자식노드를 y에 저장
  - x의 오른쪽 자식노드를 B로 만듦
  - B의 부모노드를 x로 만드는 link를 연결
  - y의 부모노드를 현재 x부모노드로 할당
  - x의 부모노드가 NIL이라면(즉, x가 루트라면)
  - y를 루트로 설정
  - 그렇지 않고 x의 부모노드가 존재한다면, 
  - x가 부모노드의 왼쪽 자식이었다면, y가 x부모노드의 왼쪽 자식노드가 되고,
  - 그렇지 않다면, y는 x의 부모노드의 오른쪽 자식이 됨
  - x가 y의 왼쪽 자식이 되게하고
  - y가 x의 부모노드가 되도록 함

```python
class Node:
    def __init__(self, key, parent):
        self.key = key
        self.left = right = None
        self.p = parent
def leftRotate(x):
    y = x.right
    x.right = y.left
    if x.p == None: 		#x가 루트
        y.p = None
    elif x.p.left == x: 	#왼쪽에 달려있던 x면
        y.p = x.p.left
    else:
        y.p = x.p.right
    y.left = x
    x.p = y
```

##### INSERT

- 보통의 BST에서처럼 노드를 INSERT한다.
- 새로운 노드 z를 red노드로 한다.
- RB-INSERT-FIXUP을 호출한다.
- 1 : 또다른 포인터 y를 사용해서 y가 x의 한칸 뒤를 쫓아 내려오록 해야 새로운 노드를 insert할 자리를 관리할 수 있다. 레드블랙트리에서 특수하게 NIL 노드를 사용하지만, 실제로 구현할때는 null이 된다.
- 3 - 7 : 새로운 노드 z가 들어갈 자리를 찾고,
- 8 : z의 parent를 y로 설정해준다.
- 9 - 10 : 예외적인 경우 y가 null이면, 새로운 노드 z는 이 트리의 루트 노드가 된다.
- 11 - 13 : y노드의 키값과 새로운 노드의 키값을 비교하여, y의 왼쪽 자식일지 오른쪽 자식일지 결정한다.
- 14 - 15 : 새로운 노드는 BST의 leaf 노드가 되기 때문에, 새로운 노드의 자식들을 null로 설정한다.
- 16 : 새로운 노드는 RED노드로 설정한다.
- 17 : RB-INSERT-FIXUP(T, z)메소드를 호출한다.
  - 새로운 노드 z의 부모노드가 RED일 경우 레드블랙트리의 요건을 만족하지 않기 때문에, 조정이 필요하다.

```
RB-INSERT(T, z)
1  y <- nil[T]
2  x <- root[T]
3  while x != nil[T]
4    do y <- x
5      if key[z] < key[x]
6        then x <- left[x]
7        else x <- right[x]
8  p[z] <- y
9  if y = nil[T]
10   then root[T] <- z
11   else if key[z] < key[y]
12          then left[y] <- z
13          else right[y] <- z
14 left[z] <- nil[T]
15 right[z] <- nil[T]
16 color[z] <- RED
17 RB-INSERT-FIXUP(T, z)
```

##### RB-INSERT-FIXUP

- 레드블랙트리의 규칙이 위반될 가능성이 있는 조건들
  - 각 노드는 red 혹은 black이다.
    - **위반 가능성 없음**
  - 루트노드는 black이다.
    - 새로운 노드 z가 루트 노드라면 규칙 위반, 아니라면 위반 가능성 없음
    - 새로운 노드 z가 루트 노드라면 간단하게 노드를 블랙으로 바꾸는 작업을 해주면 된다.
  - 모든 리프노드(즉, NIL 노드)는 black이다.
    - 새로운 노드의 자식들을 NIL노드로 설정하므로 **위반 가능성 없음**
  - red노드의 자식노드들은 전부 black이다.(즉, red노드는 연속되어 등장하지 않고)
    - **위반 될 가능성이 있다**. 부모 노드가 원래 RED였다면, RED - RED 가 되므로 위반이 발생한다.
    - 가장 큰 문제가 되는 것이 RED - RED 조건을 위반 하는 것이다.
  - 모든 노드에 대해서 그 노드로 부터 자손인 리프노드에 이르는 모든 경로에는 동일한 개수의 black노드가 존재한다.
    - 새로운 노드를 RED로 추가 했으므로, **위반 가능성 없음**

##### Loop Invariant (루프를 돌면서 변하지 않고 유지되는 조건) :

- z는 red 노드
- 오직 하나의 위반만이 존재한다.
  - 조건 2 : z가 루트노드이면서 red이거나, 또는
  - 조건 4 : z와 그 부모 p[z]가 둘 다 red 이거나.
  - 조건 4를 해결하기 위해 부모노드를 타고 올라가다 보면, 또다른 RED - RED 위반이 있을 수 있다. 최악의 경우 루트노드까지 타고올라가게 되면, 조건 2를 위반 한 것이므로 루트노드를 블랙으로 바꿔주고 종료하면 된다.

#### 종료조건 :

- 부모노드 p[z]가 black이되면 종료한다. 조건2가 위반일 경우 z를 블랙으로 바꿔주고 종료한다.

##### 문제 정의

총 6가지 case로 이 문제를 정의한다.

p[p[z]]가 반드시 존재하는 이유는 RED - RED 위반이 발생한 경우, p[z]가 RED이므로 레드블랙트리의 조건에 의해 부모인 p[p[z]]는 **블랙** 노드로 존재할 수 밖에 없다.

- 1, 2, 3 Case는 p[z]가 p[p[z]]의 왼쪽 자식인 경우
- 4, 5, 6 Case는 p[z]가 p[p[z]]의 오른쪽 자식인 경우
- Case 1, 2, 3과 4, 5, 6은 대칭적이기 때문에, 코드상에서 left와 right만 바꿔주면 된다.
- Case 1, 2, 3에 대해 집중적으로 알아본다.

##### Case 1 : z의 부모의 형제가 RED인 경우

- 새로운 노드 z의 부모가 RED이면서, 부모의 형제 노드 D가 RED인 경우이다.
- (a) - 오른쪽 자식, (b) - 왼쪽 자식
- 이 경우 부모노드와 부모노드의 형제노드를 BLACK으로 바꾸고, 할아버지 노드를 RED로 바꾼다.
- 그리고 나서, 할아버지 노드 C를 새로운 노드 z로 설정하여 위로 타고 올라가면서 레드 블랙 트리의 조건을 위반하는지를 검사한다.
- Case 1의 경우 문제가 완전히 해결되지는 않았다. z가 두칸 위로 올라가서 그 위치에서 부터 다시 해결해야 한다.

[![img](https://github.com/namjunemy/TIL/raw/master/Algorithm/img/red_black_04.png?raw=true)](https://github.com/namjunemy/TIL/blob/master/Algorithm/img/red_black_04.png?raw=true)

##### Case 2, 3 : z의 부모의 형제가 BLACK인 경우

- z의 부모의 형제가 BLACK인 경우 실제로 BLACK 노드일 수도 있고, NIL노드일 수도 있다. 따라서, 그림에서 노드의 형태로 표현하지 않았다.

- Case 2 : z가 오른쪽 자식인 경우

  - p[z]에 대해서 left-rotation한 후 원래 p[z]를 z로 만든다.
  - Case 3으로 이동

- Case 3 : z가 왼쪽 자식인 경우

  - p[p[z]]에 대해서 right-rotation을 한다.
  - p[z]를 BLACK, p[p[z]]를 RED로 바꾼다.

- **Case 1, 2, 3 정리**

  - Case 1의 문제를 해결하고 나면 문제는 종료되지 않는다. Case 2로 갈수도 있고, Case 3로 갈수도 있으며, 다시 Case 1의 문제가 반복해서 발생할 수 있다. 최악의 경우 루트노드까지 올라가서 레드블랙트리의 조건 2 루트 노드가 레드인 경우를 블랙으로 변경하면서 종료하게 된다.
  - Case 2는 발생하면, Case 3을 거쳐서 해결하면 종료된다.
  - Case 3의 경우 z의 할아버지 노드를 기준으로 right-rotate하면 문제가 해결되고, 종료 된다.
  - Case 1, 2, 3의 경우에 해당하는 것이고, Case 1에서 Case 4, 5, 6으로 넘어갈 수도 있다.

  [![img](https://github.com/namjunemy/TIL/raw/master/Algorithm/img/red_black_05.png?raw=true)](https://github.com/namjunemy/TIL/blob/master/Algorithm/img/red_black_05.png?raw=true)

##### Case 4, 5, 6

- Case 1, 2, 3은 p[z]가 p[p[z]]의 왼쪽 자식인 경우들
- Case 4, 5, 6은 p[z]가 p[p[z]]의 오른쪽 자식인 경우들
  - Case 1, 2, 3과 대칭적이므로 생략
  - 결론적으로 Case 1, 2, 3의 정리가 각각 Case 4, 5, 6으로 매칭된다.
  - Case 4의 문제를 해결하고 나면 문제가 해결된 것이 아니고, Case 4로 다시, 또는 Case 5, 6으로, Case 1, 2, 3으로 넘어갈 수도 있다. 물론 2칸씩 올라가면서 해결하게 된다.
  - Case 5의 경우 Case 6을 거쳐서 해결하면 종료된다.

##### RB-INSERT-FIXUP Code

- pesudo code
  - z는 새로운 노드
  - 1 : z의 부모가 RED인 동안 RED - RED 위반이 존재하므로 while문 수행
    - 실제로 while문의 탈출조건에서 z가 루트노드가 되더라도 루트노드의 parent가 NIL이라고 구현하지 않기 때문에, 구현하는 단계에서는 while문의 탈출조건은 `color[p[z]] = RED && p[z] != null` 이 될 것이다.
  - 2 : Case 1, 2, 3은 z의 할아버지 노드의 왼쪽자식이 z의 부모노드인 경우이다.
  - 3 : 부모의 형제를 y에 저장한다. z의 할아버지 노드의 오른쪽 자식.
  - 4 : y노드의 color가 레드인지 블랙인지에 따라서 Case1 과 Case2, 3으로 나뉜다.
  - 5 - 8 : Case 1의 경우이다. z가 RED인 상황에서 부모와 부모의 형제가 모두 RED이고, 할아버지 노드는 BLACK인 상황이다. 이 상황에서 부모와 부모의 형제노드를 BLACK으로 바꾸고, 할아버지 노드를 RED로 바꾼다. 마지막으로 할아버지 노드를 다시 새로운 노드 z로 설정하여 트리를 타고 올라가면서 문제를 해결한다.
  - 9 : Case 2, 3의 경우이다. z와 z의 부모가 RED이고, z의 부모는 z의 할아버지의 왼쪽자식인 상황에서, z의 부모의 형제노드가 NIL일수도 있고, BLACK을 가지는 노드일 수도 있다. 결국 BLACK인 노드.
  - 10 - 11 : Case 2의 경우는 z가 z의 부모의 오른쪽 자식인 경우이므로 우선적으로 z노드를 기준으로 LEFT-ROTATE연산을 거친다. 다음으로 Case 3의 처리 로직으로 넘어간다.
  - 12 - 14 : Case 3의 경우 z의 부모 노드를 BLACK으로 바꾸고, z의 할아버지 노드를 RED로 바꾼 다음, 할아버지 노드를 기준으로 RIGHT-ROTATE를 해준다.
  - 15 : Case 4, 5, 6은 z의 할아버지노드의 오른쪽지식이 z의 부모노드인 경우이다. 대칭적으로 똑같이 동작한다.
  - 16 : 결과적으로 레드블랙트리 FIXUP 메소드의 처리 로직에 따르면 Case 3또는 6에 의해서 문제를 해결하고 while문을 빠져나오게 된다. 하지만, Case 1, 4를 반복하다가 루트 노드까지 올라가서 while문이 종료되면 루트 노드는 RED이기 때문에, 마지막으로 루트 노드를 BLACK으로 만들어 준다.

```
RB-INSERT-FIXUP(T, z)
1  while color[p[z]] = RED
2    do if p[z] = left[p[p[z]]]
3        then y <- right[p[p[z]]]
4          if color[y] = RED
5            then color[p[z]] <- BLACK   >> CASE 1
6                 color[y] <- BLACK      >> CASE 1
7                 color[p[p[z]]] <- RED  >> CASE 1
8                 z <- p[p[z]]           >> CASE 1
9          else if z = right[p[z]]
10                then z <- p[z]         >> CASE 2
11                     LEFT-ROTATE(T, z) >> CASE 2
12              color[p[z]] <- BLACK     >> CASE 3
13              color[p[p[z]]] <- RED    >> CASE 3
14              RIGHT-ROTATE(T, p[p[z]]) >> CASE 3
15      else(same as then clause with "right" and "left" exchanged)
16 color[root[T]] <- BLACK
```

##### INSERT의 시간복잡도

- BST에서의 INSERT : O(logn)
- RB-INSERT-FIXUP
  - Case 1, 4에 해당할 경우 z가 2레벨 상승한다.
  - Case 2, 3, 5, 6에 해당할 경우 O(1)
  - 따라서, 트리의 높이에 비례하는 시간복잡도를 가진다.
- 즉, INSERT의 시간복잡도는 O(logn)

##### RB-INSERT-FIXUP 처리 흐름

[![img](https://github.com/namjunemy/TIL/raw/master/Algorithm/img/red_black_06.png?raw=true)](https://github.com/namjunemy/TIL/blob/master/Algorithm/img/red_black_06.png?raw=true)

##### 5-3. Red-Black Tree 03 - DELETE, FIXUP

##### DELETE

- 보통의 BST에서처럼 DELETE한다.
- 실제로 삭제된 노드 y가 red였으면 종료
- y가 black이었을 경우 RB-DELETE-FIXUP을 호출한다.
- pesudo code
  - 01 : 삭제할 노드 z의 왼쪽, 오른쪽 자식이 NULL이 아니라면 즉, 자식이 없다면
  - 02 : y에 z를 저장하고
  - 03 : 자식이 있다면, z의 Successor를 찾아서 y에 저장한다. BST에서 Successor찾는 과정과 동일
  - 04 : 01-03과정을 거치면 y는 자식이 하나이거나 없다. Successor는 자식노드가 두 개일 수 없다. y의 왼쪽 자식이 null이 아니라면
  - 05 : y의 왼쪽 자식을 x로
  - 06 : 그렇지 않다면, y의 오른쪽 자식을 x로 저장한다.
  - 07 : 그다음 y의 부모를 x의 부모로 설정한다.
  - 08 : 만약, y의 부모가 NULL이라면
  - 09 : x를 트리의 root로 설정한다.
  - 10 : y의 부모노드가 NULL이 아니고, y가 y의 부모의 왼쪽 자식노드라면
  - 11 : 저장된 x를 y의 부모의 왼쪽 자식노드로 설정한다.
  - 12 : y가 y의 부모의 오른쪽 자식노드라면, 저장된 x를 부모노드의 오른쪽 자식으로 설정한다. 여기까지가 실제로 노드를 삭제하는 작업이다.
  - 13 : 삭제하려는 노드 대신 Successor를 삭제한 경우 y와 z가 다르다. 따라서 Successor y노드의 데이터를 카피해주는 작업이 필요하다.
  - 14 - 15 : y의 데이터들을 z노드로 copy해주는 작업
  - 15번 라인까지의 작업은 BST의 DELETE작업이다. 아래의 3줄은 RBT의 경우에 해줘야하는 연산이다.
  - **삭제한 노드 y가 red 노드 였다면, RBT의 규칙에 위반 되지 않는다.**
  - 16 : 삭제한 노드 y가 BLACK 노드일 경우
    - 삭제한 노드가 루트노드인데, 그 자식인 레드노드가 올라와서 루트가 된 경우,
    - 중간의 black노드가 삭제되억서 red - red 위반이 생긴 경우,
    - 트리를 따라 내려가면서 black노드의 갯수가 일치하지 않는 경우가 생길 수 있다.
  - 17 : 문제들을 해결하기 위해 RBT-DELETE-FIXUP(T, x)를 통해서 트리의 규칙을 만족하기 위한 작업을 한다. y의 자식인 x를 넘겨서 정렬한다.
  - 18 : 삭제된 노드 y를 반환한다.

```
RB-DELETE(T, z)
01 if left[z] = nil[T] or right[z] = nil[T]
02   then y <- z
03 else y <- TREE-SUCCESSOR(z)
    
04 if left[y] != nil[T]
05   then x <- left[y]
06 else x <- right[y]

07 p[x] <- p[y]

08 if p[y] = nil[T]
09   then root[T] <- x
10 else if y = left[p[y]]
11   then left[p[y]] <- x
12 else right[p[y]] <- x

13 if y != z
14   then key[z] <- key[y]
15     copy y's satellite data into z
    
16 if color[y] = BLACK
17   then RB-DELETE-FIXUP(T, x)
18 return y    
```

##### RB-DELETE-FIXUP(T, x)

x가 NIL 노드일 수도 있다. 그리고 x가 red일 경우 쉽게 해결할 수 있다. 이 두가지를 기억한다. 실제로 DELETE에서 문제는 x가 BLACK인 경우다.

- 위반 될 수 있는 규칙 정리
  - 각 노드는 red 혹은 black이다.
    - 문제 없음
  - 루트노드는 black이다.
    - y가 루트였고, x가 red인 경우 위반된다. 하지만, 심각한 문제는 아니다.
  - 모든 리프노드(즉, NIL 노드)는 black이다.
    - 문제 없음
  - red노드의 자식노드들은 전부 black이다.(즉, red노드는 연속되어 등장하지 않고)
    - p[y]와 x가 모두 red일 경우 위반
    - x가 레드인 경우 red를 black으로 바꾸어 주면 되기 때문에 심각한 문제는 아니다.
  - 모든 노드에 대해서 그 노드로 부터 자손인 리프노드에 이르는 모든 경로에는 동일한 개수의 black노드가 존재한다.
    - 원래 y를 포함했던 모든 경로는 이제 black노드가 하나 부족하다.
      - 노드 x에 "extra black"을 부여해서 일단 조건5를 만족시킨다. 색을 두개 가지고 있게 하는 임시 방법이다.
      - 그렇게 되면 노드 x는 "double black" 혹은 "red & black"이 된다. 앞으로 해결해야하는 문제가 이 것을 블랙노드로 바꾸는 것이다.

##### 문제 해결 아이디어

- Extra black을 순차적으로 트리의 위쪽으로 올려보낸다. x의 부모 가 double black이 되는 식으로.
- x가 red & black 상태가 되면 그냥 black노드로 만들고 끝낸다.
- x가 루트가 되는 순간까지 올라가면 그냥 extra black을 제거한다.

##### Loop Invariant(루프를 돌면서 변하지 않고 유지되는 조건)

- x는 루트가 아닌 double-black노드
- w는 x의 형제노드
- w는 NIL 노드가 될수 없음 (아니면 x의 부모에 대해 조건5가 위반 됨.)

##### 문제 정의

DELETE의 경우 8가지 case로 분류할 수 있다. INSERT와 마찬가지로 1,2,3,4와 5,6,7,8은 대칭이다.

- Case 1,2,3,4 : x가 부모의 왼쪽 자식노드인 경우
  - x는 double black노드이거나, NIL 노드 일수도 있다.
  - x의 형제노드인 w노드는 반드시 존재하고, NIL일 수는 없다.
  - x는 자신의 부모의 왼쪽 자식이다.
- Case 5,6,7,8 : x가 부모의 오른쪽 자식노드인 경우

##### Case 1 - x의 형제노드 w가 RED인 경우

- Case 1,2,3,4의 공통 조건에 해당하며, 케이스 1인 경우는
- x의 형제노드 w가 RED인 경우이다. 이 경우는 자식노드가 NIL일 수 없고, BLACK 노드이다.
- 이 상황에서 문제를 해결하기 위해,
- w를 BLACK으로 p[x]를 RED로 바꾼 뒤
- p[x]에 대해서 left-rotation을 적용한다. x는 여전히 double-black 노드를 가지고 있다.
- x의 새로운 형제노드는 원래 w의 자식노드이다.
- 따라서, 새로운 w노드는 black노드이다. 이 경우 Case 2, 3, 4로 넘어가게 된다.
- 정리를 하면, Case1의 경우 x의 부모 노드에 대해서 left-rotation을 적용하면, 새로운 w노드가 red가 아닌 black이 되는 상황이라서 Case 2, 3, 4로 넘어가게 된다.

[![img](https://github.com/namjunemy/TIL/raw/master/Algorithm/img/red_black_07.png?raw=true)](https://github.com/namjunemy/TIL/blob/master/Algorithm/img/red_black_07.png?raw=true)

##### Case 2 - w는 BLACK, w의 자식들도 BLACK인 경우

- case 2, 3, 4의 경우 x의 형제노드 w가 BLACK인 경우이다. 이 중에서 w의 자식들도 모두 BLACK인 경우가 Case 2에 해당한다.
- 이 경우, x와 w가 모두 블랙이므로 부모인 B노드는 RED 일수도 있고, BLACK 일수도 있다.
- 현재 x는 double black 노드이고, w는 black 노드이다.
- 이 상황에서 x와 w로부터 black을 하나씩 뺏어서, 부모노드에게 준다.
- 결과적으로 x는 extra black이 하나 없어졌으므로 BLACK노드가 됐고, w는 black을 뺏겼으므로 RED노드가 된다.
- 다음으로 p[x]에게 extra-black 노드를 준다. 이렇게 하면, 트리의 위에서 부터 내려오면서 유지하던 BLACK노드의 갯수가 유지 된다.
- 만약 p[x]가 RED였다면, 위에서 설명했던 것처럼 red & black을 가지고 있는 노드를 BLACK노드로 만들고 끝내면 되고, p[x]가 BLACK이었다면 p[x]를 새로운 x로 해서 계속한다.
- 만약 Case1에서 Case2에 도달한 경우면 p[x]는 red였고, 따라서 새로운 x는 red & black이 되어서 종료된다.
- 하지만 Case2로 바로 온 경우에 p[x]가 원래 BLACK이었다면, p[x]가 double black이 되므로 반복해서 문제를 해결해야 할 수도 있다.(뒤에서 설명) 다만, extra-black이 한 level 올라갔다.

[![img](https://github.com/namjunemy/TIL/raw/master/Algorithm/img/red_black_08.png?raw=true)](https://github.com/namjunemy/TIL/blob/master/Algorithm/img/red_black_08.png?raw=true)

##### Case 3 - w는 BLACK, w의 왼쪽자식이 RED

- w를 RED로, w의 왼쪽자식노드를 BLACK으로 바꾼다.
- w에 대해서 right-rotation을 적용한다.
- x의 새로운 형제 w는 오른자식이 RED이다. 이것은 경우 4에 해당한다.

[![img](https://github.com/namjunemy/TIL/raw/master/Algorithm/img/red_black_09.png?raw=true)](https://github.com/namjunemy/TIL/blob/master/Algorithm/img/red_black_09.png?raw=true)

##### Case 4 - w는 BLACK, w의 오른쪽자식이 RED

- w의 색을 현재 p[x]의 색으로(unknown color)
- p[x]를 BLACK으로, w의 오른자식을 BLACK으로 바꾼다.
- p[x]에 대해서 left-rotation을 적용한다.
- x의 extra-black을 제거하고 종료한다.
- 이렇게 되면, double-black노드가 없어졌음에도 불구하고, 기존의 A노드를 지나는 블랙노드의 갯수가 로테이션 전과 똑같아 진다. 그리고 나머지 C와 E를 지나는 블랙노드의 갯수도 기존과 동일하게 유지된다.

[![img](https://github.com/namjunemy/TIL/raw/master/Algorithm/img/red_black_10.png?raw=true)](https://github.com/namjunemy/TIL/blob/master/Algorithm/img/red_black_10.png?raw=true)

##### RB DELETE FIXUP pesudo code

- 레드블랙트리에서 실제로 삭제한 노드는 y이다. 삭제한 노드 y의 자식인 x를 넘겨주면서 Delete Fixup을 하게 된다.
- 01 : 만약 x가 루트노드이거나, x가 레드노드라면 While문을 빠져나가서 x를 BLACK으로 만들어주고 종료하면 된다.
- 02 : While문 안에서는 크게 둘로 나뉘어지게 된다. 만약 x가 x의 부모노드의 왼쪽 자식이라면 Case 1, 2, 3, 4에 해당하며 부모노드의 오른쪽 자식이라면 Case 5, 6, 7, 8에 해당한다.
- 03 : 노드 x의 형제노드인 w를 저장한다. x가 p[x]의 왼쪽 자식이므로, w는 오른쪽 자식 노드가 된다.
- 04 : 형제 노드인 w노드가 RED인 경우가 Case 1에 해당한다.
- 05 - 08 : Case1의 경우 w노드를 BLACK으로 만들고, p[x]노드를 RED로 만든 다음, p[x]를 기준으로 LEFT-ROTATE한다. 새로운 w는 p[x]의 right가 되므로 새로 저장한다. 이때, 새로운 w노드는 BLACK 이므로(p[x]가 RED로 변경됨) 다시 While문으로 들어왔을 때, Case2, 3, 4로 가게 된다.
- 09 : Case 2, 3, 4를 구분하게 된다. w의 왼쪽, 오른쪽 자식노드가 둘다 BLACK인 경우 Case2에 해당한다.
- 10 - 11 : 위에서 학습한 내용과 같이 w와 x로 부터 black을 하나씩 뺏어서 부모 노드에게 전달한다. 그렇게 하기 위해서 w는 RED노드가 되고, p[x]를 x로 만들어 준다. p[x]가 RED였다면 다시 While문을 돌지 않고 x를 RED로 만든 뒤에 종료하면 되고, p[x]가 BLACK이었다면 x를 p[x]로 놓고 double-black 노드가 된 x를 다시 반복해서 처리해주면 된다.
- 12 : w의 오른쪽 자식이 BLACK이고, 왼쪽 자식이 RED인 경우 Case 3에 해당한다.
- 13 - 16 : RIGHT-ROTATE의 대상인 두 노드의 색을 exchange 하고(w를 RED로, w의 왼쪽 자식노드를 BLACK으로 바꾸고), w를 기준으로 RIGHT-ROTATE 한다. 이렇게 되면 w는 p[x]의 새로운 오른쪽 자식노드가 되고, 그것의 색은 RED이다. 그리고 Case 4로 바로 넘어 간다.
- 17 - 20 : LEFT-ROTATE의 대상인 두 노드의 색을 exchange 하고(w의 색을 p[x]의 색으로, p[x]를 BLACK으로) w의 오른쪽 자식노드의 색을 BLACK으로 바꾼다. 그 다음 p[x]를 기준으로 LEFT-ROTATE를 수행한다.
- 21 : x라는 포인터 변수를 root[T]로 변경하여 Case 4가 끝나면 while문이 종료되도록 한다. 실제 트리에는 변화가 없다. 트리의 루트가 변한것도 아니다.
- 22 : Case 5, 6, 7, 8을 대칭적으로 처리한다.
  - x가 p[x]의 오른쪽 자식인 경우이다.
- 23 : 트리의 루트의 색을 BLACK으로 변경하는 것은 언제 해도 문제가 되지 않는다.

```
RB-DELETE-FIXUP(T, x)
01 while x != root[T] and color[x] = BLACK
02   do if x = left[p[x]]
03        then w <- right[p[x]] 
04          if color[w] = RED
05            then color[w] <- BLACK                                  // Case1
06                 color[p[x]] <- RED                                 // Case1
07                 LEFT-ROTATE(T, p[x])                               // Case1
08                 w <- right[p[x]]                                   // Case1
09          if color[left[w]] = BLACK and color[right[w]] = BLACK
10            then color[w] <- RED                                    // Case2
11                 x <- p[x]                                          // Case2
12          else if color[right[w]] = BLACK 
13              then color[left[w]] <- BLACK                          // Case3
14                   color[w] <- RED                                  // Case3
15                   RIGHT-ROTATE(T, w)                               // Case3
16                   w <- right[p[x]]                                 // Case3
17            color[w] <- color[p[x]]                                 // Case4
18            color[p[x]] <- BLACK                                    // Case4
19            color[right[w]] <- BLACK                                // Case4
20            LEFT-ROTATE(T, p[x])                                    // Case4
21            x <- root[T]                                            // Case4
22        else (same as then clause with "right" and "left" exchanged)
23 color[x] <- BLACK
```

[![img](https://github.com/namjunemy/TIL/raw/master/Algorithm/img/red_black_12.png?raw=true)](https://github.com/namjunemy/TIL/blob/master/Algorithm/img/red_black_12.png?raw=true)

##### RB DELETE FIXUP - Case 흐름

- 전체 케이스는 1 - 8의 경우이지만 1,2,3,4와 5,6,7,8은 대칭적인 관계이므로 1,2,3,4에 대해서만 그린 흐름이다.
- 처음부터 Case 4의 경우에 해당하면, left-rotation과 extra-black노드를 뺏는 것으로 바로 Case가 종료가 된다.
- Case 3으로 가면 right-rotation으로 Case 3을 처리하고, Case 4로 상황이 바뀐다.
- Case 1으로 가면, Case 1이 해결되고 Case 2, 3, 4로 넘어간다.
- 처음부터 Case 2로 가는 경우에는 바로 종료되지 않고 차이가 있다.
- Case 2가 반복되는 동안 extra-black노드는 계속해서 트리의 위로 이동한다. 이 상황에서 Case 1, 3, 4로 이동하게 되면 흐름에 따라 2 step 이내에 종료되게 된다.
- 물론, Case 5, 6, 7, 8로 넘어가서 Case 2의 대칭인 Case 6의 경우와 왔다갔다 할 수도 있고, Case 5, 7, 8로 이동하여 끝날 수도 있다.

[![img](https://github.com/namjunemy/TIL/raw/master/Algorithm/img/red_black_11.png?raw=true)](https://github.com/namjunemy/TIL/blob/master/Algorithm/img/red_black_11.png?raw=true)

##### 시간복잡도

- BST에서의 DELETE : O(logn)
- RB-DELETE-FIXUP : O(logn)
  - 가장 최악의 경우인 Case2와 6이 반복되는 경우에도 최대 트리의 높이만큼 실행된다.
- 따라서, DELETE와 FIXUP을 합쳐도 O(logn)의 시간이 된다.



**B-Tree**

skewed tree 문제점을 해결하기 위한 해결방안 중 하나입니다.

node는 둘보다 많은 child node를 가질 수 있으며, 한 node가 여러 element를 가질 수 있습니다.

B-Tree는 M(Minimum)이라는 양수를 가집니다.

1. root는 element를 최소한 1개까지 가질 수 있지만 다른 node들은 최소한 m개의 element를 가져야 합니다.
2. node 내의 element 갯수의 최댓값은 2m입니다.
3. 모든 node의 element는 작은 값부터 정렬된 상태로 array에 담겨있습니다.
4. node가 가지는 subtree는 (node 내의 element 갯수 + 1)개입니다.
5. non-leaf node에서 index i에 위치한 element는 subtree i의 모든 element보다 크고 subtree i+1의 모든 element 값보다 작습니다.
6. 모든 leaf node는 같은 깊이에 있습니다.

탐색: node 내의 element를 선형탐색하여 target을 찾고, 못 찾을 땐 처음으로 만나는 target보다 큰 값의 index가 i면 subtree[i]에 대하여 반복한다.

삽입: 탐색과 같은 방식으로 진행하다 leaf에서 target보다 처음으로 커지는 element 앞으로 삽입한다. element 갯수가 maximum+1이 되면, 가운데 element를 parent로 보내버립니다. root까지 가버리면 새로운 root를 만듭니다.

삭제: 1) child가 없는데 못찾으면 False, child가 없는데 찾으면 단순 삭제, child가 있는데 찾았다면 직전 subtree의 가장 큰 element와 swap 후 아래에서 삭제합니다. child가 있는데 root에서 못찾았다면 subtree로 들어가 반복합니다. 이러다 node의 element 갯수가 minimum-1이 된다면 직전 subtree, 직후 subtree 혹은 형제에게서 빌려오거나 합쳐버립니다.

삽입/삭제/탐색 모두 log(n)



**Selection Sort**

```
selection_sort():
    for i in range(n):
        min_idx = i
        for j in range(i + 1, n):
            if a[j] < a[min_idx]:
                min_idx = j
        a[i], a[min_idx] = a[min_idx], a[i]
```

너무 간단합니다. O(N2)입니다.



**Insertion Sort**

```
insertion_sort():
    for i in range(1, n):
        key = a[i]
        j = i - 1
        while j >= 0 and a[j] > key:
            a[j + 1] = a[j]
            j -= 1
        a[j + 1] = key
```

array 앞의 초기에 1칸짜리 구역을 지정하고 한 칸씩 오른쪽으로 늘리면서 해당 item을 왼쪽 구간의 올바른 위치에 넣는것입니다. 마찬가지로 O(N2)입니다.



**Bubble Sort**

```
bubble_sort():
    for i in range(n):
        for j in range(n - i - 1):
            if a[j] > a[j + 1]:
                a[j], a[j + 1] = a[j + 1], a[j]
```

뒤에서 i번째 칸을 위해 맨 앞부터 올바른 값을 swap을 반복하며 가져오길 반복합니다. O(N2) 이고 위 두 정렬보다 성능이 더 나쁩니다.



**Merge Sort**

```
merge_sort(a):
    n = len(a)
    if n <= 1:
        return a
    mid = n // 2
    g1 = merge_sort(a[:mid])
    g2 = merge_sort(a[mid:])
    i1 = 0
    i2 = 0
    ia = 0
    while i1 < len(g1) and i2 < len(g2):
        if g1[i1] < g2[i2]:
            a[ia] = g1[i1]
            i1 += 1
        else:
            a[ia] = g2[i2]
            i2 += 1
        ia += 1
    while i1 < len(g1):
        a[ia] = g1[i1]
        i1 += 1
        ia += 1
    while i2 < len(g2):
        a[ia] = g2[i2]
        i2 += 1
        ia += 1
    return a
```

분할정복으로 분해된 sub-array들을 한 쌍씩 쭉 합쳐주는겁니다. O(NlogN) 이지만 같은 시간복잡도의 다른 정렬들과 다르게 추가적인 memory를 필요로 합니다.



**Quick Sort**

```
quick_sort(a, start_idx, end_idx):
    if start_idx >= end_idx:
        return;
    pivot_idx = random.randint(start_idx, end_idx)
    pivot_val = a[pivot_idx]
    a[pivot_idx], a[end_idx] = a[end_idx], a[pivot_idx]
    store_idx = start_idx
    for i in range(start_idx, end_idx):
        if a[i] < pivot_val:
            a[i], a[store_idx] = a[store_idx], a[i]
            store_idx += 1
    a[store_idx], a[end_idx] = a[end_idx], a[store_idx]
    quick_sort(a, start_idx, store_idx - 1)
    quick_sort(a, store_idx + 1, end_idx)
```

O(N)O(N)의 extra memory를 허용하게 하면 더 쉽게할 수 있지만 위처럼 만들면 extra memory는 starck frame의 O(logN)만 필요합니다.

평균적으로 O(NlogN) 의 시간복잡도를 가지지만, 최악의 경우 O(N2) 의 시간복잡도를 가집니다.

시간복잡도에 대한 증명은 [여기](https://www.khanacademy.org/computing/computer-science/algorithms/quick-sort/a/analysis-of-quicksort)를 참고하세요. 근데 교수님 수업에서 적분까지 해가면서 strict하게 증명했던 것 같은데 필기가 남아있지 않네요… 나중에 그때 그 내용 어디서 찾으면 추가할게요.



**Heap Sort**

```
heapify(a, idx, heap_size):
    largest = idx
    left_idx, right_idx = 2 * idx + 1, 2 * idx + 2
    if left_idx < heap_size and a[left_idx] > a[largest]:
        largest = left_idx
    if right_idx < heap_size and a[right_idx] > a[largest]:
        largest = right_idx
    if largest != idx:
        a[largest], a[idx] = a[idx], a[largest]
        heapify(a, largest, heap_size)


heapsort(a):
    n = len(a)
    for i in range((n - 1) // 2, -1, -1):
        heapify(a, i, n)
    for i in range(n - 1, 0, -1):
        a[0], a[i] = a[i], a[0]
        heapify(a, 0, i)
```

이건 코드를 좀 열심히 봐야 이해가 가더군요. 일단 `heapify()` 는 heap을 array로 표현했을 때 idx 위치에 있는 node의 left child, right child와 비교해서 더 셋 중 가장 큰 node를 parent 자리에 위치시키는 겁니다. 이걸 array의 뒤에서부터 해주면 아래에서 자리가 올바르지 않은 node 들이 쭉 올라와서 제자리를 찾으며 정렬이 됩니다. 그리고 두 번째 for문에서는 정렬된 heap에서 max 값인 root를 반복적으로 추출해서 array의 뒤에 위치시키는 겁니다.

complete binary tree에서 left child가 `2*idx+1`, right child가 `2*idx+2`를 index로 가지는 것은 귀납법으로 증명 가능하며, heapify를 `(n-1)//2`부터 하는 이유는 해당 node가 바로 child를 가질 수 있는 마지막 node이기 때문입니다.

##### Counting Sort

Count Sort 는 말 그대로 몇 개인지 개수를 세어 정렬하는 방식이다. 정렬하고자 하는 값 중 **최대값에 해당하는 값을 size 로 하는 임시 배열** 을 만든다. 만들어진 배열의 index 중 일부는 정렬하고자 하는 값들이 되므로 그 값에는 그 값들의 **개수** 를 나타낸다. 정렬하고자 하는 값들이 몇 개씩인지 파악하는 임시 배열이 만들어졌다면 이 임시 배열을 기준으로 정렬을 한다. 그 전에 임시 배열에서 한 가지 작업을 추가적으로 수행해주어야 하는데 큰 값부터 즉 큰 index 부터 시작하여 누적된 값으로 변경해주는 것이다. 이 누적된 값은 정렬하고자 하는 값들이 정렬될 index 값을 나타내게 된다. 작업을 마친 임시 배열의 index 는 정렬하고자 하는 값을 나타내고 value 는 정렬하고자 하는 값들이 정렬되었을 때의 index 를 나타내게 된다. 이를 기준으로 정렬을 해준다. 점수와 같이 0~100 으로 구성되는 좁은 범위에 존재하는 데이터들을 정렬할 때 유용하게 사용할 수 있다.

| Space Complexity | Time Complexity |
| ---------------- | --------------- |
| O(n)             | O(n)            |



##### Radix Sort

정렬 알고리즘의 한계는 O(n log n)이지만, 기수 정렬은 이 한계를 넘어설 수 있는 알고리즘이다. 단, 한 가지 단점이 존재하는데 적용할 수 있는 범위가 제한적이라는 것이다. 이 범위는 **데이터 길이** 에 의존하게 된다. 정렬하고자 하는 데이터의 길이가 동일하지 않은 데이터에 대해서는 정렬이 불가능하다. 숫자말고 문자열의 경우도 마찬가지이다. (불가능하다는 것은 기존의 정렬 알고리즘에 비해 기수 정렬 알고리즘으로는 좋은 성능을 내는데 불가능하다는 것이다.)

기수(radix)란 주어진 데이터를 구성하는 기본요소를 의미한다. 이 기수를 이용해서 정렬을 진행한다. 하나의 기수마다 하나의 버킷을 생성하여, 분류를 한 뒤에, 버킷 안에서 또 정렬을 하는 방식이다.

기수 정렬은 `LSD(Least Significant Digit)` 방식과 `MSD(Most Significant Digit)` 방식 두 가지로 나뉜다. LSD 는 덜 중요한 숫자부터 정렬하는 방식으로 예를 들어 숫자를 정렬한다고 했을 때, 일의 자리부터 정렬하는 방식이다. MSD 는 중요한 숫자부터 정렬하는 방식으로 세 자리 숫자면 백의 자리부터 정렬하는 방식이다.

두 가지 방식의 Big-O 는 동일하다. 하지만 주로 기수정렬을 이야기할 때는 LSD 를 이야기한다. LSD 는 중간에 정렬 결과를 볼 수 없다. 무조건 일의 자리부터 시작해서 백의 자리까지 모두 정렬이 끝나야 결과를 확인할 수 있고, 그 때서야 결과가 나온다. 하지만 MSD 는 정렬 중간에 정렬이 될 수 있다. 그러므로 정렬하는데 걸리는 시간을 줄일 수 있다. 하지만 정렬이 완료됬는지 확인하는 과정이 필요하고 이 때문에 메모리를 더 사용하게 된다. 또 상황마다 일관적인 정렬 알고리즘을 사용하여 정렬하는데 적용할 수 없으므로 불편하다. 이러한 이유들로 기수 정렬을 논할 때는 주로 LSD 에 대해서 논한다.

| Space Complexity | Time Complexity |
| ---------------- | --------------- |
| O(n)             | O(n)            |

++

**기수정렬은 낮은 자리수부터 비교하여 정렬해 간다는 것을 기본 개념으로 하는 정렬 알고리즘입니다.** **기수정은 비교 연산을 하지 않으며 정렬 속도가 빠르지만 데이터 전체 크기에 기수 테이블의 크기만한 메모리가 더 필요합니다.**

 

■ **정렬 방식**

 

**1. 0~9 까지의 Bucket(Queue 자료구조의)을 준비한다.**

**2. 모든 데이터에 대하여 가장 낮은 자리수에 해당하는 Bucket에 차례대로 데이터를 둔다.** 

**3. 0부터 차례대로 버킷에서 데이터를 다시 가져온다.** 

**4. 가장 높은 자리수를 기준으로 하여 자리수를 높여가며 2번 3번 과정을 반복한다.** 

 

![img](https://t1.daumcdn.net/cfile/tistory/99A6D33359CE331015)

 

**아래의** **8개 데이터에 대하여 기수 정렬을 시도해 보겠습니다. 위의 그림과 같이 각 숫자에 해당하는 Queue공간을 할당하고 진행합니다.**

 

![img](https://t1.daumcdn.net/cfile/tistory/9957483359CE33AB14)

**먼저 1의 자리 숫자부터 시도를 합니다. 데이터 순서대로 각 1의 자리에 해당되는 Queue에 데이터가 들어가게 됩니다. 15같은 경우는 1의 자리가 5이므로 Queue 5에 들어가는 방식입니다.**

 

![img](https://t1.daumcdn.net/cfile/tistory/990D3A3359CE34472B)

 

**위의 그림처럼** **다시 0번 Queue부터 차례대로 데이터를 가지고 와서 원래의 배열에 넣어주게 됩니다.**

**1의 자리에 대한 정렬이 완료되었습니다. 다음으로는 10의 자리에 대하여 같은 작업을 반복합니다.**

 

![img](https://t1.daumcdn.net/cfile/tistory/9913633359CE34C223)

**마찬가지로 각 데이터의 10의 자리에 해당되는 Queue에 데이터를 위치 시킵니다. 그런 다음 0번 Queue부터 차례대로 다시 데이터를 가지고 옵니다.**

 

![img](https://t1.daumcdn.net/cfile/tistory/99C8DB3359CE35D412)

**최종적으로 정렬이 완료가 됩니다.**

■ **특징**

##### 1. 시간 복잡도는 O(dn, d는 자릿수)

**2. 자리수가 고정되어 있어서 안정성이 있는 정렬 방식**



#### Sorting Algorithm's Complexity 정리

| Algorithm      | Space Complexity | (average) Time Complexity | (worst) Time Complexity |
| -------------- | ---------------- | ------------------------- | ----------------------- |
| Bubble sort    | O(1)             | O(n^2)                    | O(n^2)                  |
| Selection sort | O(1)             | O(n^2)                    | O(n^2)                  |
| Insertion sort | O(1)             | O(n^2)                    | O(n^2)                  |
| Merge sort     | O(n)             | O(nlogn)                  | O(nlogn)                |
| Heap sort      | O(1)             | O(nlogn)                  | O(nlogn)                |
| Quick sort     | O(1)             | O(nlogn)                  | O(n^2)                  |
| Count sort     | O(n)             | O(n)                      | O(n)                    |
| Radix sort     | O(n)             | O(n)                      | O(n)                    |

**Topological Sort**

Directed Graph에서 정점들의 선행 순서를 위배하지 않으면서 모든 정점을 나열하는 알고리즘입니다. Scheduler처럼 작업의 순서가 정해져 있을 때 각각의 작업이 완료되어야 끝나는 문제에 주로 쓰입니다.

```
topological_sort():
    q = Queue()
    for i in range(n):
        if in_degree[n] == 0: 
	    q.enqueue(i)
    for i in range(n):
        if q.is_empty():
            error
        x = q.dequeue()
        answer[i] = x
        for j in adj[x]:
            in_degree[j] -= 1
            if in_degree[j] == 0:
                q.enqueue(j)
```

BFS랑 비슷한데, inDegree를 이용하여 enqueue 합니다. 시간복잡도는 O(V+E) 입니다.

1. indegree 0인 정점 큐에 모두 넣음
2. 정점개수 만큼 반복->큐에서 원소뺌, 그 원소로 outdegree에 위치한 정점들의 indegree감소 시킴. 이때 indegree가 0이 된 정점 생기면 큐에 넣어줌
3. 큐에서 빼는 순서가 위상정렬임. 

if) 정점개수 만큼 돌아가기 전에 큐가 비어버리면 불가능한거(사이클 생겼단 소리), 중간에 q의 원소가 두개 이상이면 결과도 두개 이상이란거

**Single Source Shortest Path**

하나의 출발점에서 각 정점까지 도달하는데 비용을 계산하여 최단경로를 구하는 것입니다. 기본적으로 Directed Graph 구조를 가지고 설명하며, Undirected일 경우 같은 weight의 directed edge 두 개로 바꾸고 시작합니다.



**Dijkstra Algorithm**

Priority Queue를 이용하여 하나의 정점으로부터 인접한 간선들을 확장해 나가는 방식입니다. 음수 가중치를 갖는 간선이 없어야 합니다.

d[v] 배열을 모두 ∞으로 초기화하고, 시작점의 d[v] 값을 0으로하고 Priority Queue에 넣습니다.

Queue가 빌 때까지 minimum을 뽑고, 해당 정점에 adjacent한 정점의 d[v]값을 계산하여 업데이트합니다.

```
dijkstra(adjacency_list, v):
    n = len(adjacency_list)
    d = [INF for _ in range(n)]
    visited = [False for _ in range(n)]
    d[v] = 0
    q = PriorityQueue()
    q.enqueue((d[v], v))
    while not q.is_empty():
        value, cur = q.dequeue()
        if value > d[cur]: continue
        visited[cur] = True
        for dest, weight in adjacency_list:
            new_v = d[curr] + weight
            if (not visited[dest]) and new_v < d[dest]:
                d[dest] = new_v
                q.enqueue((d[dest], dest))
```

실제로 priority queue를 heap으로 구현하고 path 구하려면 predecessor 배열 만들긴 해야하는데 아무튼 이런 식으로하면 됩니다.

heap에 삽입이 O(logE), 그리고 삽입이 정점 갯수에 한해서 이루어지므로 O(VlogE), 값 갱신은 간선 갯수에 한해서 이루어지므로 O(ElogE), 합쳐서 O((E+V)logE), V<=E2V<=E2이므로 O((E+V)logV)입니다. 피보나치 힙을 사용하면 더 줄일 수 있다고 하네요.

정당성 증명

방문된 정점까지의 거리는 최소 거리임을 증명하면 되는데, 초기에 정점 하나만 있을 때 만족하므로 귀납법 + 귀류법으로 풉니다.

K+1 단계에서 정점 u를 방문하였는데 그 거리가 실제 최소 거리가 아니라고 하면, 다른 정점 u’가 방문되지 않은 채 존재하여 u까지의 실제 최소 거리를 잇는 정점으로 존재한다는 것인데, 그렇게 되면 (중략 w, w’가 등장하는 부분) d[u’]가 d[u]보다 작게 되는데 그러면 알고리즘 진행과정에서 u’가 u보다 먼저 방문되었어야 하므로 contradiction이 생기므로 증명 완료됩니다.



**Floyd-Warshall’s Algorithm**

얘는 Single Source Shortest Path 뿐만 아니라 All Pairs Shortest Paths를 구해줍니다.

```
floyd_warshall():
    for i in range(E):
        for j in range(E):
            for k in range(E):
                if adj[i][k] > adj[j][i] + adj[i][k]:
                    adj[j][k] = adj[j][i] + adj[i][k]
```

코드만 보셔도 아실 겁니다. O(E3)입니다. 중요한 점은 가운데 지나가는 정점이 맨 바깥 for문에 위치해야 한다는 것입니다.



#####  bellman-Ford: 음의 가중치 있는 최단거리

::(v-1번 동안 반복) i+1개 정점을 거쳐오는 최단거리 갱신(적절한 방문순서 알 수 없으니 모두 확인)

if v번째 돌렸는데 갱신되는 값이 있다? =>음의 싸이클 존재함

```
BellmanFord(G,w,s):
//초기화 과정
for each u in G.V:  			 //노드를 초기화 하기
      distance[v] = inf    	 	 //모든 노드의 최단거리를 무한으로 지정
      parent[v] = null       	 //모든 노드의 부모 노드를 널값으로 지정
distance[s] = 0 				 //출발점의 최단거리는 0으로 지정한다
//거리측정 과정
for i from 1 to len(G.V):   	 //노드의 숫자만큼(V-1번)
     for each (u,v) in G.E:  	 //모든 변을 체크해 최단 거리를 찾아본다.
          if distance[u] + w[(u,v)] < distance[v]:   
          //만약 u를 경유하여 v로 가는 거리가 현재 v의 최단 거리보다 짧으면
               distance[v] = distance[u] + w[(u,v)]  //그 거리를 v의 최단거리로 지정
               parent[v] = u    //u를 v의 부모 노드로 지정
//음수 사이클 체크 과정 
for each (u,v) in G.E:			//V번째 돌렸을때 갱신되는 곳 있으면 음의 싸이클 존재
     if distance[u] + w[(u,v)] < distance[v]:
          return false 			//음수 사이클을 확인하고 알고리즘을 정지
return distance[], parent[]
```

---

##### 문자열?

나중에 추가하고, 우선 이번엔 RB트리, B트리까지만



##### 출처

https://github.com/WeareSoft/tech-interview/blob/master/contents/datastructure.md

https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/DataStructure

https://rokrokss.com/post/2019/04/06/%EB%A9%B4%EC%A0%91-%EC%A4%80%EB%B9%84-%EC%A0%84%EC%82%B0-%EC%88%98%EC%97%85-%EC%B4%9D%EC%A0%95%EB%A6%AC.html

https://namu.wiki/w/%EB%B2%A8%EB%A8%BC-%ED%8F%AC%EB%93%9C%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98