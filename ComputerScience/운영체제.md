# 운영체제

##### 프로그램(program)

​	 ::어떤 작업을 위해 실행할 수 있는 파일

##### 프로세스(Process)

​	:: 컴퓨터에서 연속적으로 실행되고 있는 컴퓨터 프로그램(디스크로부터 메모리에 적재되어 CPU의 할당을 받을 수 있는 것)

- 의미
  - 메모리에 올라와 실행되고 있는 프로그램의 인스턴스(독립적인 개체)
  - 운영체제로부터 시스템 자원을 할당받는 작업의 단위
  - 즉, 동적인 개념으로는 실행된 프로그램을 의미

- 할당받는 시스템 자원의 예
  - CPU 시간
  - 운영되기 위해 필요한 주소 공간
  - Code(프로그램 명령어), Data=static(전역변수, array, structure 등), Stack(함수의 매개변수, return value, 로컬 변수 등 임시자료), Heap(동적으로 할당되는 메모리)의 구조로 되어 있는 독립된 메모리 영역

[![img](https://github.com/WeareSoft/tech-interview/raw/master/contents/images/process.png)](https://github.com/WeareSoft/tech-interview/blob/master/contents/images/process.png)

- 특징
  - 프로세스는 각각 독립된 메모리 영역(Code, Data, Stack, Heap의 구조)을 할당 받는다.
  - 기본적으로 프로세스당 최소 1개의 스레드(메인 스레드)를 가지고 있다.
  - 각 프로세스는 별도의 주소 공간에서 실행되며, 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없다.
  - 한 프로세스가 다른 프로세스의 자원에 접근하려면 프로세스 간의 통신(IPC, Inter-Process Communication)을 사용해야 한다. (Ex. 파이프, 파일 소켓 등을 이용한 통신 방법 이용)

##### PCB(Process Control Block)

::PCB는 특정 프로세스에 대한 중요한 정보를 저장하고 있는 운영체제의 자료구조이다. 운영체제는 프로세스를 관리하기 위해 프로세스의 생성과 동시에 고유한 PCB를 생성한다. 프로세스는 CPU를 할당받아 작업을 처리하다가도 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU를 반환해야 하는데, 이때 작업의 진행 상황을 모두 PCB에 저장하게 된다. 그리고 다시 CPU를 할당받게 되면 PCB에 저장되어 있던 내용을 불러와 이전에 종료됐던 시점부터 다시 작업을 수행한다.

- PCB에 저장되는 정보
  - 프로세스 식별자(Process ID, PID): 프로세스 식별번호
  - 프로세스 상태: new, ready, running, waiting, terminated등의 상태를 저장
  - 프로그램 카운터: 프로세스가 다음에 실행할 명령어의 주소
  - CPU 레지스터
  - CPU 스케줄링 정보: 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
  - 메모리 관리 정보: 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함
  - 입출력 상태 정보: 프로세스에 할당된 입출력 장치들과 열린 파일 목록
  - 어카운팅 정보: 사용된 CPU 시간, 시간제한, 계정번호 등

##### 스레드(Thred)

​	::프로세스 내에서 실행되는 여러 흐름의 단위(프로세스의 실행 단위)

- 의미
  - 프로세스의 특정한 수행 경로
  - 프로세스가 할당받은 자원을 이용하는 실행의 단위

- [![img](https://github.com/WeareSoft/tech-interview/raw/master/contents/images/thread.png)](https://github.com/WeareSoft/tech-interview/blob/master/contents/images/thread.png)

- 특징
  - 스레드는 프로세스 내에서 각각 Stack만 따로 할당받고 Code, Data, Heap 영역은 공유한다.
  - 스레드는 한 프로세스 내에서 동작되는 여러 실행의 흐름으로, 프로세스 내의 주소 공간이나 자원들(힙 공간 등)을 같은 프로세스 내에 스레드끼리 공유하면서 실행된다.
  - 같은 프로세스 안에 있는 여러 스레드들은 같은 힙 공간을 공유한다. 반면에 프로세스는 다른 프로세스의 메모리에 직접 접근할 수 없다.
  - 각각의 스레드는 별도의 레지스터와 스택을 갖고 있지만, 힙 메모리는 서로 읽고 쓸 수 있다.
  - 한 스레드가 프로세스 자원을 변경하면, 다른 이웃 스레드(sibling thread)도 그 변경 결과를 즉시 볼 수 있다.

##### 멀티 프로세스 대신 멀티 스레드를 사용하는 이유

​	::쉽게 설명하면, 프로그램을 여러개 키는 것보다 하나의 프로그램 안에서 여러 작업을 해결하는 것.(하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 향상시키는 것)

[![img](https://github.com/WeareSoft/tech-interview/raw/master/contents/images/multi-thread.png)](https://github.com/WeareSoft/tech-interview/blob/master/contents/images/multi-thread.png)

1. 자원의 효율성 증대
   - 멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행할 경우, 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있다. (프로세스 간의 Context Switching시 단순히 CPU 레지스터 교체 뿐만 아니라 RAM과 CPU 사이의 캐시 메모리에 대한 데이터까지 초기화되므로 오버헤드가 크기 때문)
   - 스레드는 프로세스 내의 메모리를 공유하기 때문에 독립적인 프로세스와 달리 스레드 간 데이터를 주고 받는 것이 간단해지고 시스템 자원 소모가 줄어들게 된다.
2. 처리 비용 감소 및 응답 시간 단축
   - 프로세스 간의 통신(IPC)보다 스레드 간의 통신의 비용이 적으므로 작업들 간이 통신의 부담이 줄어든다.(스레드는 Stack 영역을 제외한 모든 메모리를 공유하기 때문)
   - 프로세스 간의 전환 속도보다 스레드 간의 전환 속도가 빠르다. (Context Switching시 스레드는 Stack 영역만 처리하기 때문)

***주의할 점!***

- **동기화 문제**
- 스레드 간의 자원 공유는 전역 변수(데이터 세그먼트)를 이용하므로 함께 상용할 때 충돌이 발생할 수 있다.

Q1) 스택을 스레드마다 독립적으로 할당하는 이유

​	스택은 함수 호출시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고, 이는 독립적인 실행 흐름이 추가되는 것이다. 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다.



Q2) PC Register를 스레드마다 독립적으로 할당하는 이유

​	PC 값은 스레드가 명령어의 어디까지 수행하였는지를 나타내게 된다. 스레드는 CPU를 할당 받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다. 따라서 PC register를 독립적으로 할당한다.

##### 멀티 스레딩

- 장점
  - 프로세스를 이용하여 동시에 처리하던 일을 스레드로 구현할 경우 메모리 공간과 시스템 자원 소모가 줄어들게 된다.
  - 스레드간의 통신이 필요한 경우에도 별도의 자원을 이용하는 것이 아니라 전역변수의 공간 또는 동적으로 하당된 공간인 Heap 영역을 이용하여 데이터를 주고받을 수 있다. 그렇기 때문에 프로세스 간 통신 방법에 비해 스레드 간의 통신 방법이 훨씬 간단하다. 
  - 스레드의 context switch는 프로세스의 context switch와는 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다.
  - 따라서 시스템의 throughtput이 향상되고 자원 소모가 줄어들며 자연스럽게 응답 시간이 단축된다.
- 단점
  - 멀티 프로세스 기반으로 프로그래밍 할때는 프로세스간 공유하는 자원이 없기 때문에 동일한 자원에 동시에 접근하는 일이 없었지만, 멀티 스레딩 기반으로 프로그래밍 할 때는 이 부분을 신경써 줘야함
  - 서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있음
  - 따라서 멀티스레딩 환겨에서는 동기화 작업이 필요함. 동기화를 통해 작업 처리 순서를 컨트롤 하고 공유 자원에 대한 접근을 컨트롤 하는 것. 하지만 이로 인해 병목현상이 발생하여 성능이 저하될 가능성이 있으므로 과도한 락으로 인한 병목현상을 줄여야함.

##### 멀티 스레드 vs 멀티 프로세스

​	::멀티 스레드는 멀티 프로세스보다 적은 메모리 공간을 차지하고, 문맥 전환이 빠르다는 장점이 있지만, 오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있다는 점과 동기화 문제를 안고 있음. 반면 멀티 프로세스 방식은 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다는 장점이 있지만, 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지한다는 단점이 존재한다. 이 두 가지는 동시에 여러 작업을 수행한다는 점에서 같지만 적용해야 하는 시스템에 따라 적합/부적합이 구분된다. 따라서 대상 시스템의 특징에 따라 적합한 동작 방식을 선택하고 적용해야 한다.

예시 생각해보기

##### Thread-safe

- 의미
  - 멀티스레드 환경에서 여러 스레드가 동시에 하나의 객체 및 변수(공유 자원)에 접근할 때, 의도한 대로 동작하는 것을 말한다.
  - 이러한 상황을 "Thread-safe하다" 라고 표현함.

- Thread-safe하게 구현하기

  - Thread-safe하기 위해서는 공유 자원에 접근하는 임계영역(critical section)을 동기화 기법으로 제어해줘야 한다.(이를 '상호배제'라고 한다.)
  - 동기하 기법으로는 Mutex나 Semaphore 등이 있다.

- Reentrant

  - Reentrant는 재진입성 이라는 의미로, 어떤 함수가 Reentrant하다는 것은 여러 스레드가 동시에 접근해도 언제나 같은 실행 결과를 보장한다는 의미이다.
  - 이를 만족하기 위해서는 해당 서브루틴에서는 공유자원을 사용하지 않으면 된다.(예를 들어 정적(전역) 변수를 사용하거나 반환하면 안되고 호출시 제공된 매개변수만으로 동작해야한다.)
  - 따라서 Reentrant 하다면 Thread-safe 하지만, 그 역은 성립하지 않음


##### 프로세스 동기화

- Critical Section(임계영역): 멀티스레딩의 문제점에서 나오듯, 동일한 자원을 동시에 접근하는 작업(Ex 공유하는 변수 사용, 동일 파일 사용 등)을 실행하는 코드 영역을 Critical Section이라 칭함.
- Critical Section Problem(임계영역 문제)
  - 프로세스들이 Critical Section을 함께 사용할 수 있는 프로토콜을 설계하는 것.
  - Requirements(해결을 위한 기본 조건)
    - Mutual Exclusion(상호 배제): 프로세스 P1이 Critical Section에서 실행중이라면, 다른 프로세스들은 그들이 가진 Critical Section에서 실행될 수 없다.
    - Progress(진행): Critical Section에서 실행중인 프로세스가 없고, 별도의 동작이 없는 프로세스들만 Critical Section 진입 후보로서 참여될 수 있다.
    - Bounded waiting(한정된 대기): P1이 Critical Section에 진입 신청 후부터 받아들여질 때까지, 다른 프로세스들이 Critical Section에 진입하는 횟수는 제한이 있어야 한다.
- 해결책
  - Lock
    - 하드웨어 기반 해결책으로써, 동시에 공유 자원에 접근하는 것을 막기 위해 Critical Section에 진입하는 프로세스는 Lock을 획득하고, Critical Section을 빠져 나올 때 Lock을 방출함으로써 동시에 접근이 되지 않도록 함
    - 한계: 다중처리기 환경에서는 시간적인 효율성 측면에서 적용할 수 없음
  - Semaphores(세마포): SW상에서 Critical Section 문제를 해결하기 위한 동기화 도구
    - Counting Semaphores: 가용한 개수를 가진 자원에 대한 접근 제어용으로 사용되며, 세마포는 그 가용한 자원의 개수로 초기화 됨. 자원을 사용하면 세마포가 감소, 방출하면 세마포가 증가함
    - Binary Semaphores: Mutex라고도 부르며, 상호배제의(Mutual Exclution)의 머릿글자를 따서 만들어짐. 이름 그대로 0과 1사이의 값만 가능하며, 다중 프로세스들 사이의 Critical Section 문제를 해결하기 위해 사용됨.
    - 단점: Busy waiting, 초기 진입 코드 계속 반복 실행해서 CPU 낭비 했었는데, 세마포에서 Critical Section에 진입을 시도했지만 실패한 프로세스에 대해 block시킨 뒤, 자리가 날 때 다시 깨우는 방식으로 해결됨

##### 동기화 객체의 종류

- 스레드 동기화 방법
  1. 실행 순서의 동기화
     - 스레드의 실행순서를 정의하고, 이 순서에 반드시 따르도록 하는 것
  2. 메모리 접근에 대한 동기화
     - 메모리 접근에 있어서 동시접근을 막는 것
     - 실행의 순서가 중요한 상황이 아니고, 한 순간에 하나의 스레드만 접근하면 되는 상황을 의미
- 동기화 기법의 종류
  1. 유저 모드 동기화
     - 커널의 힘을 빌리지 않는(커널 코드가 실행되지 않는) 동기화 기법
     - 성능상 이점, 기능상의 제한
     - Ex) 크리티컬 섹션 기반의 동기화, 인터락 함수 기반의 동기화
  2. 커널 모드 동기화
     - 커널에서 제공하는 동기화 기능을 활용하는 방법
     - 커널 모드로의 변경이 필요하고 이는 성능 저하로 이어짐, 다양한 기능 활용 가능
     - Ex) 뮤텍스 기반의 동기화, 세마포어 기반의 동기화, 이름있는 뮤텍스 기반의 프로세스 동기화, 이벤트 기반의 동기화



##### 뮤텍스(Mutex) vs 세마포어(Semaphore)

- 뮤텍스
  - 공유된 자원의 데이터를 **여러 스레드가** 접근하는 것을 막는 것
  - 상호배제라고도 하며, Critical Section을 가진 스레드의 Running time이 서로 겹치지 않도록 각각 단독으로 실행하게 하는 기술이다.
  - 다중 프로세스들의 공유 리소스에 대한 접근을 조율하기 위해 synchronized 또는 lock을 사용한다. (즉, 뮤텍스 객체를 두 스레드가 동시에 사용할 수 없다.)
- 세마포어
  - 공유된 자원의 데이터를 **여러 프로세스가** 접근하는 것을 막는 것
  - 리소스 상태를 나타내는 간단한 카운터로 생각할 수 있다.
    - 운영체제 또는 커널의 한 지정된 저장장치 내의 값이다.
    - 일반적으로 비교적 긴 시간을 확보하는 리소스에 대해 이용한다.
    - 유닉스 시스템 프로그래밍에서 세마포어는 운영체제의 리소스를 경쟁적으로 사용하는 다중 프로세스에서 행동을 조정하거나 또는 동기화 시키는 기술이다.
  - 공유 리소스에 접근할 수 있는 프로세스의 최대 허용치만큼 동시에 사용자가 접근하여 사용할 수 있다.
  - 각 프로세스는 세마포어 값을 확인하고 변경할 수 있다.
    - a. 사용중이지 않는 자원의 경우 그 프로세스가 즉시 자원을 사용할 수 있다.
    - b. 이미 다른 프로세스에 의해 사용중이라는 사실을 알게 되면 재시도 하기 전에 일정 시간을 기다려야 한다.
    - 세마포어를 사용하는 프로세스는 그 값을 확인하고, 자원을 사용하는 동안에는 그 값을 변경함으로써 다른 세마포어 사용자들이 기다리도록 해야한다.
  - 세마포어는 이진수를 사용하거나, 또는 추가적인 값을 가질 수도 있다.

- 차이
  - 가장 큰 차이점은 관리하는 동기화 대상의 개수(Mutex는 동기화 대상이 오직 하나뿐일 때, Semaphore는 동기화 대상이 하나 이상일 때 사용한다.)
  - Semaphore는 Mutex가 될 수 있지만 Mutex는 Semaphore가 될 수 없다.(Mutex는 상태가 0, 1뿐인 binary Semaphore)
  - Semaphore는 소유할 수 없는 반면, Mutex는 소유가 가능하며 소유주가 이에 대한 책임을 가진다.(Mutex의 경우 상태가 두개 뿐인 lock이므로 lock을 가질 수 있다.??)
  - Mutex의 경우 Mutex를 소유하고 있는 스레드가 이 Mutex를 해제할 수 있다. 하지만 Semaphore의 경우 이러한 Semaphore를 소유하지 않는 스레드가 Semaphore를 해제할 수 있다.??
  - Semaphore는 시스템 범위에 걸쳐있고 파일시스템상의 파일 형태로 존재하는 반면 Mutex는 프로세스 범위를 가지며 프로세스가 종료될 때 자동으로 Clean up된다.

##### 교착상태(Deadlock)

- 교착상태란?
  - 첫 번째 스레드는 두 번째 스레드가 들고 있는 객체의 락이 풀리기를 기다리고 있고(ready queue), 두 번째 스레드 역시 첫 번째 스레드가 들고 있는 객체의 락이 풀리기를 기다리는 상황(Critical Section에서 실행되는 프로세스는 진입 대기 중인 프로세스가 실행되어야만 빠져나올 수 있는 상황)을 일컸는다.
  - 모든 스레드가 락이 풀리기를 기다리고 있기 때문에, 무한 대기 상태에 빠지게 된다. 이런 스레드를 교착상태에 빠졌다고 한다.
- 교착 상태의 4가지 조건
  1. 상호배제(mutual exclusion)
     - 한 번에 한 프로세스만 공유 자원을 사용할 수 있다.
     - 좀 더 정확하게는, 공유 자원에 대한 접근 권한이 제한된다. 자원의 양이 제한되어 있더라도 교착상태는 발생할 수 있다.
  2. 들고 기다리기(hold and wait) = 점유대기
     - 공유 자원에 대한 접근 권한을 갖고 있는 프로세스가, 그 접근 권한을 양보하지 않은 상태에서 다른 자원에 대한 접근 권한을 요구할 수 있다.
  3. 선취(preemption) 불가능 = 비선점
     - 한 프로세스가 다른 프로세스의 자원 접근 권한을 강제로 취소할 수 없다.
  4. 대기 상태의 사이클(circular wait) = 순환대기
     - 두 개 이상의 프로세스가 자원 접근을 기다리는데, 그 관계에 사이클이 존재한다.
- 교착상태 방지
  - 위 4가지 조건들 가운데 하나를 제거하면 된다.
  - 공유 자원 중 많은 경우가 한 번에 한 프로세스만 사용할 수 있기 때문에(Ex 프린트) 1번 조건은 제거하기 어렵다.
  - 대부분의 교착상태 방지 알고리즘은 4번 조건, 즉 대기 상태의 사이클이 발생하는 일을 막는 데에 초점이 맞춰져 있다.

cf) 모니터

- Semaphore 보다 높은 레벨의 객체로, mutex나 semaphore로 구성된 lock을 갖고 해제하고, 그 다음 스레드가 실행되고 이 과정을 처리하는 함수들을 구현해 놓은 것입니다.

#### 스케줄러

- 스케줄링 Queue
  - Job Queue: 현재 시스템 내에 있는 모든 프로세스의 집합
  - Ready Queue: 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
  - Device Queue: Device I/O 작업을 대기하고 있는 프로세스의 집합
- 각각의 Queue에 프로세스들을 넣고 빼주는 스케줄러 3가지
  - 장기스케줄러(Long-term scheduler or job scheduler)
    - 메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장됨. 이 pool에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue로 보낼지 결정하는 역할.
    - 메모리와 디스크 사이의 스케줄링을 담당
    - 프로세스에 memory(및 각종 리소스)를 할당(admit)
    - degree of Multiprogramming 제어(실행중인 프로세스의 수 제어)
    - 프로세스의 상태 (new -> ready(in memory) )
    - cf) 메모리에 프로그램이 너무 많이 올라가도, 너무 적게 올라가도 성능이 좋지 않음. 참고로 time sharing sysyem에서는 장기 스케줄러가 없고, 곧바로 메모리에 올라가 ready 상태가 됨
  - 단기스케줄러(Short-term scheduler or CPU scheduler)
    - CPU와 메모리 사이의 스케줄링을 담당
    - Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정.
    - 프로세스에 CPU를 할당(scheduler dispatch)
    - 프로세스의 상태(ready -> running -> waiting -> ready)
  - 중기스케줄러(Medium-term scheduler or Swapper)
    - 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄(swapping)
    - 프로세스에게서 memory를 deallocate
    - degree of Multiprogramming 제어
    - 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러.
    - 프로세스의 상태(ready -> suspended)
    - cf) suspended(stopped): 외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태를 의미. 프로세스 전부 디스크로 swap out 된다. blocked 상태는 다른 I/O작업을 기다리는 상태이기 때문에 스스로 ready state로 돌아갈 수 있지만, 이 상태는 외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없다.

- 동기 <-> 비동기
  - 동기(Synchronous)란?
    - '동기'라고 하면 다수의 개체들이 동일(일정)한 무언가를 가지는 것. 또는 무언가가 동일(일정)하게 되는 것.
    - 그 무언가는 '상태'가 될 수 있고, '행위'가 될 수 있고, '시간', '속도', '주기', '출현' 등이 될 수 있음
    - 여기서 말하는 '동기'는 두개의 프로세스가 데이터를 주고 받을 때, 주고 받는 '순서'(시간)가 일정하다는 것을 뜻한다.
  - 동기식, 동기적이다.
    - 어떤 작업을 요청했을 때 그 작업이 종료될 때까지 기다린 후 다음 작업을 수행한다.
    - 데이터를 주고받는 '순서'가 중요할 때 사용된다.
    - 요청한 작업만 처리하면 되기 때문에 전체적인 수행 속도는 빠를 수 있다.(일만 하면 된다.)
    - 한 작업애 대한 시간이 길어질 경우, 전체 응답이 지연될 수 있다.
  - 비동기식, 비동기적이다.
    - 어떤 작업을 요청했을 때 그 작업이 종료될 때까지 기다리지 않고(작업을 위임하고), 다음 작업을 수행한다. 요청했던 작업이 끝나면 결과를 받고, 그에 따른 추가 작업이 있다면 수행한다.
    - 요청 순서에 상관없이, 동시에 다수의 작업을 처리할 수 있다.
    - 작업이 끝날 때 따로 이벤트를 감지하고 결과를 받아 그에 따른 추가 작업을 해줘야하기 때문에, 비교적 느릴 수 있다.
    - I/O 작업이 잦고, 빠른 응답속도를 요구하는 프로그램에 적합하다.
  - 추가 설명:https://asfirstalways.tistory.com/348

- CPU 스케줄링(스케줄링 대상은 Ready Queue에 있는 프로세스들)

  - FCFS(First Come First Served)

    - 먼저 온 순서대로 처리.
    - 비선점형(Non-Preemptive) 스케줄링
    - 문제점: 소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상이 발생

  - SJF(Shorted - Job - First)

    - CPU burst time이 짧은 프로세스에게 선 할당

    - 비선점형(Non-Preemptive) 스케줄링(이거 선점형도 되지 않음? => 이건 shortest remaining time first:SRTF 라고 부른대)

    - 문제점

      - 효율성을 추구하는게 가장 중요하지만, 특정 프로세스가 지나치게 차별 받으면 안됨. 사용 시간이 긴 프로세스는 영원히 할당 못받을수도(starvation)

        => sol) 에이징 기법(대상에 나이 부여, 할당 받지 못하고 기다리는 동안 나이 증가, 우선순위에 나이를 일정비율 반영)

      - 프로세스가 얼마만큼의 CPU burst를 가지는지 미리 알수가 없어서 실제로 사용하기 힘듦

  - Priority Scheduling

    - 우선순위가 가장 높은 프로세스에게 CPU를 할당하는 스케줄링
    - 선점형(Preemptive): 더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU를 선점
    - 비선점형(Non-Preemptive): 더 높은 우선순위의 프로세스가 도착하면 Ready Queue의 Head에 넣음
    - 문제점: starvation

  - Round-Robin(RR) Scheduling

    - 현대적인 CPU 스케줄링
    - 시간을 쪼개서 프로세스 진행
    - 쪼갠 동일한 시간을 Time quantum, Time Slice라 부름
    - Time-sharing system(시분할/시공유 시스템)
    - 할당 시간이 지나면 프로세스는 선점당하고 Ready queue의 제일 뒤에 가서 다시 줄을 섬
    - RR은 CPU사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적
    - RR이 가능한 이유는 프로세스의 context를 save할 수 있기 때문
    - Preemptive scheduling: 끝나지 않아도 타임 퀀텀이 지나가면 다른 프로세스가 실행
    - 장점
      - Response time이 빨라짐. n개의 프로세스가 ready queue에 있고 할당 시간이 q(time quantum)인 경우 각 프로세스는 q단위로 CPU 시간의 1/n을 얻는다. 즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다.
      - 프로세스가 기다리는 시간이 CPU를 사용할 만큼 증가한다. 공정한 스케줄링이라 할 수 있음
      - 주의: 설정한 time quantum이 너무 커지면 FCFS와 같아짐, 너무 작으면 잦은 context switch로 overhead 발생. 적당한 time quantum이 중요

    - Example

    | Process | Burst Time |
    | :-----: | :--------: |
    |   P1    |     24     |
    |   P2    |     3      |
    |   P3    |     3      |

    - Time Quantum = 4msec
    - AWT = (6+4+7)/3 = 17/3 = 5.66 msec
    - Time Quantum이 1이면 AWT이 변함! 퀀텀을 얼마나 잡아야 성능이 좋을까?
    - Performance depends on the size of the time quantum (Δ), 타임 퀀텀에 의존적
      - Δ → ∞는 FCFS와 동일
      - Δ → 0는 Processor sharing : 스위칭이 빈번하게 돌아서 같이 도는 것처럼 보임(* context switching overhead가 빈번하게 발생)
    - Example: Average turnaround time (ATT)

    | Process | Burst Time |
    | :-----: | :--------: |
    |   P1    |     6      |
    |   P2    |     3      |
    |   P3    |     1      |
    |   P4    |     7      |

    - Average Turnaround Time
    - ATT = (15+9+3+17)/4 = 11.0 msec (Δ = 1)
    - ATT = (15+8+9+17)/4 = 12.25 msec (Δ = 5)
    - 데이터에 따라 성능이 다름

  - Multilevel Queue Scheduling

    - Process group: 프로세스를 그룹화. 은행에서 간단한 업무 / 대출 업무 구분해서 받는 것과 유사
      1. Sysyem processes: OS에서 작업. 가상메모리, IO, 통신(가장 빨리 처리해야 함)
      2. Interactive processes: 사용자랑 대화하는 프로그램. 게임(<-> 컴파일 하는 것은 대화하지 않는 프로그램임)
      3. Interactive editing processes: 편집하는 프로그램
      4. Batch processes: 대화형이 아닌 프로세스. 꾸러미로 일괄적으로 처리
      5. Student processes
    - Single ready queue -> Several separate queues
      - 각각의 Queue에 절대적 우선순위 존재 or CPU time을 각 Queue에 차등배분
      - 그룹에 따라 다르게 스케줄링
      - 각 Queue는 독립된 scheduling 정책

  - Multilevel Feedback Queue Scheduling

    - 복수 개의 Queue
    - 다른 Queue로의 점진적 이동
      - 모든 프로세스는 하나의 입구로 진입
      - 너무 많은 CPU time 사용시 다른 Queue로
      - 기아 상태 우려시 우선순위 높은 Queue로
      - 한 Queue에만 있지 않고 옮겨가는 방식



##### Context Switching

- Context Switching이란?
  - 현재 진행하고 있는 Task(Process, Thread)의 상태를 저장하고 다음 진행할 Task의 상태 값을 읽어 적용하는 과정을 말한다.
  - 과정
    1. Task의 대부분 정보는 Register에 저장되고 PCB(Process Control Block)로 관리된다.
    2. 현재 실행하고 있는 Task의 PCB정보를 저장한다.(Process Stack, Ready Queue)
    3. 다음 실행할 Task의 PCB 정보를 읽어 Register에 적재하고 CPU가 이전에 진행했던 과정을 연속적으로 수행할 수 있다.
  - Context Switching Cost(Process vs Thread)
    - Process Context Switching 비용 > Thread Context Switching 비용
    - Thread는 Stack 영역을 제외한 모든 메모리를 공유하므로 Context Switching 수행시 Stack 영역만 변경하면 되기 때문에 비용이 적게 든다.

##### 메모리 관리 전략

- 배경: 각각의 프로세스는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. 단지, 운영체제만이 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않는다.
- Swapping: 메모리의 관리를 위해 사용되는 기법. 표준 Swapping 방식으로는 RR과 같은 스케줄링의 다중 프로그래밍 환경에서 CPU 할당 시간이 끝난 프로세스의 메모리를 보조 기억장치(Ex 하드디스크)로 내보내고 다른 프로세스의 메모리를 불러 들일 수 있다.(주 기억장치(RAM)으로 불러오는 과정을 swap-in, 보조기억장치로 내보내는 과정을 swap-out 이라고함. swap에는 디스크 전송시간이 필요하기 때문에 현재에는 메모리 공간이 부족할때 Swapping이 시작됨)
- 단편화(Segmentation): 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면, 프로세스들이 차지하는 메모리 틈 사이에 사용하지 못할 만큼의 작은 자유공간들이 늘어나게 되는데, 이것이 단편화
  - 외부 단편화: 남는 공간을 합치면 요청을 만족시키지 않지만 연속직이지 않기 때문에 메모리 할당 불가능. 물리 메모리(RAM)에서 사이사이 남는 공간들을 모두 합치면 충분한 공간이 되는 부분들이 분산되어 있을때 발생한다고 볼 수 있음
  - 내부 단편화:  partition보다 살짝 작은 메모리가 할당되어 남는 공간이 버려짐. 예를 들어 메모리 분할 자유공간이 10,000B있고 Process A가 9,998B 사용하게 되면 2B라는 차이가 존재하고, 이 현상을 내부 단편화라 칭함
- 압축: 외부 단편화를 해소하기 위해 프로세스가 사용하는 공간들을 한쪽으로 몰아, 자유공간을 확보하는 방법론이지만, 작업 효율이 좋지 않음

#페이징, 세그멘테이션 보충하기

- Paging(페이징):

  -  하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 없애는 메모리 관리 방법. 외부 단편화와 압축 작업을 해소하기 위해 생긴 방법론으로, 물리 메모리는 Frame이라는 고정 크기로 분리되어 있고, 논리메모리(프로세스가 점유하는)는 페이지라 불리는 고정 크기의 블록으로 분리된다.(페이지 교체 알고리즘에 들어가는 페이지)

  - 페이징 기법을 사용함으로써 논리 메모리는 물리 메모리에 저장될 때, 연속되어 저장될 필요가 없고 물리 메모리의 남는 프레임에 적절히 배치됨으로 외부 단편화를 해결할 수 있는 큰 장점이 있다. 하나의 프로세스가 사용하는 공간은 여러개의 페이지로 나뉘어서 관리되고(논리메모리에서), 개별 페이지는 순서에 상관없이 물리 메모리에 있는 프레임에 mapping되어 저장된다고 볼 수 있다.

  - 단점: 내부 단편화 문제의 비중이 늘어나게 된다. 예를들어 페이지 크기가 1,024B이고, 프로세스 A가 3172B의 메모리를 요구한다면, 3개의 페이지 프레임 하고도 100B가 남기 때문에 총 4개의 프레임이 필요함. 결론적으로 4번째 프레임에는 924B의 여유 공간이 남게되는 내부 단편화 문제가 발생

- Segmentation(세그멘테이션)
  - 페이징에서처럼 논리 메모리와 물리 메모리를 같은 크기의 블록이 아닌, 서로 다른 크기의 논리적 단위인 세그먼트(Segment)로 분할. 사용자가 두 개의 주소로 지정(세그먼트 번호 + 변위). 세그먼트 테이블에는 각 세그먼트의 기준(세그먼트의 시작 물리 주소)과 한계(세그먼트의 길이)를 저장
  - 단점: 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 자유 공간들이 많은 수의 작은 조각들로 나누어져 못쓰게 될 수도 있다.(외부 단편화)

##### 가상메모리

![img](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/interview/5.png)

- 다중 프로그래밍을 실현하기 위해서는 많은 프로세스들을 동시에 메모리에 올려두어야함. 가상메모리는 **프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법**이며, 프로그램이 물리 메모리보다 커도 된다는 주요 장점이 있음

- 개발 배경: 실행되는 코드의 전부를 물리 메모리에 존재시켜야 했고, 메모리 용량보다 큰 프로그램은 실행시킬 수 없었다. 또한 여러 프로그램을 동시에 메모리에 올리기에는 용량의 한계와, 페이지 교체등의 성능 이슈가 발생하게 된다. 또한, 가끔만 사용되는 코드가 차지하는 메모리들을 확인할 수 있다는 점에서, 불필요하게 전체의 프로그램 전체가 메모리에 올라와 있어야 하는게 아니라는 것을 알 수 있음
- if 프로그램의 일부분만 메모리에 올릴 수 있다면?
  - 물리 메모리 크기에 제약받지 않게 됨
  - 더 많은 프로그램을 동시에 실행할 수 있게 됨. (이에 따라 응답시간은 유지되고, CPU 이용률과 처리율은 높아짐)
  - swap에 필요한 입출력이 줄어들기 때문에 프로그램들이 빠르게 실행됨
- 하는 일: 가상 메모리는 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것으로 정리할 수 있음. 이로써 작은 메모리를 가지고도 얼마든지 큰 가상 주소 공간을 프로그래머에게 제공할 수 있음
- 가상 주소 공간
  - 한 프로세스가 메모리에 저장되는 논리적인 모습을 가상메모리에 구현한 공간. 프로세스가 요구하는 메모리 공간을 가상메모리에서 제공함으로써 현재 직접적으로 필요치 않은 메모리 공간은 실제 물리 메모리에 올리지 않는 것으로 물리 메모리를 절약 할 수 있음
  - 예를 들어, 한 프로그램이 실행되며 논리 메모리로 100KB가 요구 되었음. 근데 실행에 필요한 메모리 공간(cede, data, stack, heap)의 합이 40KB라면, 실제 물리 메모리에는 40KB만 올라가 있고, 나머지 60KB 만큼은 필요시에 물리메모리에 요구한다고 이해하면 됨.
- TLB(Translation Lookaside Buffer): Page Table은 Main memory에 적재되며 CPU와 Main memory 사이의 TLB는 페이지 테이블의 최근 쓰인 엔트리들을 캐싱하는 역할
- Difference between L1 and L2 cache: CPU는 여러 레벨의 캐시를 가지고 있음. 캐시는 CPU에서 Main memory로 접근하는데 걸리는 시간을 절약하기 위해 메인 메모리의 instance를 가져와 캐싱함. CPu와의 거리에 따라 L1, L2, L3 캐시로 나뉘며, 낮은 레벨의 캐시를 먼저 참조하게 됨.

##### 페이지

- 프로세스간의 페이지 공유(가상 메모리는...)
  - 시스템 라이브러리가 여러 프로세스들 사이에 공유될 수 있도록 한다.  각 프로세스들은 공유 라이브러리를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가 있는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다.
  - 프로세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 통신할 수 있음. 이또한, 각 프로세스들은 각자 자신의 주소공간처럼 인식하지만, 실제 물리 메모리는 공유되고 있음.
  - fork()를 통한 프로세스 생성 과정에서 페이지들이 공유되는 것을 가능하게 함.
- Demand Paging(요구 페이징)
  - 프로그램 실행 시작시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략. 가상메모리 시스템에서 많이 사용됨. 그리고 가상 메모리는 대개 페이지로 관리됨. 요구 페이징을 사용하는 가상 메모리에서는 실행과정에서 필요해질 때 페이지들이 적재됨. 한 번도 접근되지 않은 페이지는 물리 메모리에 적재되지 않음.
  - 프로세스 내의 개별 페이지들은 페이저(pager)에 의해 관리됨. 페이저는 프로세스 실행에 실제 필요한 페이지들만 메모리로 읽어 옮으로써, 사용되지 않을 페이지를 가져오는 시간낭비와 메모리 낭비를 줄일 수 있음.

##### 페이지 교체

- 개요: 요구페이징에서 언급된대로 프로그램 실행시에 모든 항목이 물리 메모리에 올라오지 않기 떄문에, 프로세스의 동작에 필요한 페이지를 요청하는 과정에서 page fault가 발생하게 되면, 원하는 페이지를 보조저장장치에서 가져오게 됨. 하지만, 만약 물리 메모리가 모두 사용중인 상황이라면, 페이지 교체가 이루어져야 함.(또는, 운영체제가 프로세스를 강제 종료하는 방법도 있음)
- 기본 틀
  1. 디스크에서 필요한 페이지의 위치를 찾음
  2. 빈 페이지 프레임을 찾음
     1. 페이지 교체 알고리즘을 통해 희생될(victim) 페이지를 고름
     2. 희생될 페이지를 디스크에 기록하고, 관련 페이지 테이블을 수정
  3. 새롭게 비워진 페이지 테이블 내 프레임에 새 페이지를 읽어오고, 프레임 테이블을 수정
  4. 사용자 프로세스 재시작

##### 페이지 교체 알고리즘

- FIFO 페이지 교체
  - 가장 간단한 페이지 교체 알고리즘, 먼저 온 순서대로 페이지 교체 시점에 먼저 나감
  - 장점: 이해하기 쉽고, 프로그래밍 하기 쉬움
  - 단점: 
    - 오래된 페이지가 항상 불필요하지 않은 정보를 포함하지 않을 수 있음(초기 변수 등)
    - 처음부터 활발하게 사용되는 페이지를 교체해서 페이지 부재율을 높이는 부작용을 초래할 수 있음
    - Belady의 모순: 페이지를 저장할 수 있는 페이지 프레임의 갯수를 늘려도 되려 페이지 부재가 더 많이 발생하는 모순이 존재함.
- Optimal Page Replacement(OPT, 최적 페이지 교체)
  - Belady의 모순을 확인한 이후 최적 교체 알고리즘에 대한 탐구가 진행되어쏙, 모든 알고리즘보다 낮은 페이지 부재율을 보이며 belady의 모순이 발생하지 않음. 이 알고리즘의 핵시은 앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체 하는 것. 주로 비교 연구 목적을 위해 사용
  - 장점: 알고리즘 중 가장 낮은 페이지 부재율을 보장
  - 단점: 구현의 어려움이 있음. 모든 프로세스의 메모리 참조의 계획을 미리 파악할 방법이 없기 때문
- Least-Recently-Used Page Replacement(LRU 페이지 교체)
  - 최적 알고리즘의 근사 알고리즘으로, 가장 오랫동안 사용되지 않은 페이지를 선택하여 교체
  - 대체적으로 FIFO보다 우수하고, OPT보다는 그렇지 못한 모습
- Least-Frequently-Used Page Replacement(LFU 페이지 교체)
  - 참조 횟수가 가장 적은 페이지를 교체하는 방법. 활발하게 사용되는 페이지는 참조 횟수가 많아질거라는 가정에서 만들어진 알고리즘.
  - 어떤 프로세스가 특정 페이지를 집중적으로 사용하다가 다른 기능을 사용하게 되면 더이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋나는 시점이 발생할 수 있음
  - 최적(OPT) 페이지 교체를 제대로 근사하지 못하기 때문에 잘 쓰이지 않음
- Most-Frequently-Used Page Replacement(MFU 페이지 교체)
  - 참조 횟수가 가장 적은 페이지가 최근에 메모리에 올라왔고, 앞으로 계속 사용될 것이라는 가정에 기반
  - OPT페이지 교체에 제대로 근사하지 못하기 때문에 잘 쓰이지 않음

##### 캐시

:: 캐시 메모리는 속도가 빠른 장치와 느린 장치간의 속도차에 따른 병목 현상을 줄이기 위한 범용 메모리임. 이러한 역할을 수행하기 위해서는 CPU가 어떤 데이터를 원할 것인가를 어느정도 예측할 수 있어야함. 캐시의 성능은 작은 용량의 캐시 메모리에 CPU가 이후에 참조할, 쓸모 있는 정보가 어느정도 들어있느냐에 따라 좌우되기 때문. 이 때 **적중률(Hit-rate)을 극대화 시키기 위해 데이터 지역성(Locality)의 원리를 사용**함. 지역성의 전제조건으로 프로그램은 모든 코드나 데이터를 균등하게 Access하지 않는다는 특성을 기본으로 함. 즉, Locality란 기억 장치 내의 정보를 균일하게 Access하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성임

- 시간 지역성: 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성
- 공간 지역성: 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성
- Caching line
  - 언급했듯이, 캐시는 프로세서 가까이에 위치하면서 빈번하게 사용되는 데이터를 놔두는 장소. 하지만 캐시가 아무리 가까이 있더라도 찾고자 하는 데이터가 어느 곳에 저장되어 있는지 몰라 모든 데이터를 순회해야 한다면 시간이 오래 걸리게 됨. 즉, 캐시에 목적 데이터가 저장되어 있다면 바로 접근하여 출력하 수 있어야 캐시가 의미 있어짐. 때문에 **캐시에 데이터를 저장할 때 특정 자료구조를 사용하여 묶음으로 저장하게 되는데 이를 캐싱라인 이라고함.** 다양한 주소에 있는 데이터를 사용하므로 빈번하게 사용하는 데이터의 주소는 흩어져 있음. 따라서 캐시에 저장하는 데이터에는 데이터의 메모리주소 등을 기록해 둔 태그를 달아놓을 필요가 있음. 이러한 태그들의 묶음을 캐싱 라인이라고 하고 메모리로부터 가져올 때도 캐싱라인을 기준으로 가져옴.
  - 대표적인 방식 세가지 (찾아보기!)
    1. Full Associative
    2. Set Associative
    3. Direct Map

##### IPC(InterProcess Communication)

::프로세스간의 통신 방법을 제공함

- IPC 기법

  - Message Queue
  - Shared Memory
  - Pipe
  - Signal
  - Semaphore
  - Socket

- Pipe

  - 기본 파이프는 단방향 통신
  - fork()로 자식 프로세스 만들었을때, 부모와 자식간의 통신

  [![img](https://github.com/cheese10yun/TIL/raw/master/assets/process-pipe.png)](https://github.com/cheese10yun/TIL/blob/master/assets/process-pipe.png)

  - 부모 프로세스에서 fd[1]을 기반으로 데이터를 생성
  - 자식 프로세스에서 fd[0]을 기반으로 데이터를 읽을 수 있음
  - **단방향 통신이다**
  - 실제 데이터가 전달되는 pipe는 커널 영역에 존재한다.

- 메시지 큐

  - 큐 정책 그대로 FIFO 정책으로 데이터 전송
  - 먼저 넣은 데이터가 먼저 읽혀진다.
  - 메시지큐는 양방향이 가능

- 메시지 큐, 파이프

  - mesage queue는 부모/자식이 아니라, 어느 프로세스간에더라도 데이터 송수신이 가능
  - 먼저 넣은 데이터가

- 공유 메모리

  [![img](https://github.com/cheese10yun/TIL/raw/master/assets/shared-memory.png)](https://github.com/cheese10yun/TIL/blob/master/assets/shared-memory.png)

  - 노골적으로 kernel space에 메모리 공간을 만들고, 해당 공간을 변수처럼 쓰는 방식
  - message queue 처럼 FIFO 방식이 아니라. 해당 메모리 주소를 마치 변수처럼 접근하는 방식
  - 공유 메모리 key를 가지고, 여러 프로세스가 접근 가능

- Signal

  - 커널 또는 프로세스에서 다른 프로세스에 어떤 이벤트가 발생되었는지를 알려주는 기법
  - 시그널은 미리 정의된 이벤트이다.
  - 서로 다른 프로세스들이 시그널 이벤트를 이용해서 프로세스간의 통신이 가능하다.
    - 미리 정의된 시그널 중에서 아무 동작도 하지 않은 시그널을 통해서 시그널을 정의해서 사용 한다.
  - 프로세스 관련 코드에 관련 시그널 핸들러를 등록해서, 해당 시그널 처리 실행
    - 시그널 무시
    - 시그널 블록(블록을 푸는 순간, 프로세스에 해당 시그널 전달)
    - 등록된 시그널 핸들러로 특정 동작 수행
    - 등록된 시그널 핸들러가 없다면, 커널에 기본 동작 수행

- Socket

  - 소켈은 네트워크 통신을 위한 기술
  - 기본적으로는 클라이언트와 서버등 두 개의 다른 컴퓨터간의 네트워크 기반 통신을 위한 기술
  - 소켓을 하나의 컴퓨터 안에서, 두 개의 프로세스 간에 통신 기법으로 사용 가능

- 정리

  - 여러 프로세스 동시 실행을 통한 성능 개선, 복잡한 프로그램을 위해 프로세스간 통신 필요
  - 프로세스간 공간이 완전분리
  - 프로세스간 통신을 위한 특별한 기법 IPC 지원
  - 대부분의 IPC 기법은 커널 커널 공간을 활용
    - 이유: 커널 공간은 프로세스간의 공유가 가능